{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SageMaker Debugger and SageMaker Experiments for iterative model pruning\n",
    "\n",
    "This notebook demonstrates how we can use [SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html) and [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) to perform iterative model pruning. Let's start first with a quick introduction into model pruning.\n",
    "\n",
    "State of the art deep learning models consist of millions of parameters and are trained on very large datasets. For transfer learning we take a pre-trained model and fine-tune it on a new and typically much smaller dataset. The new dataset may even consist of different classes, so the model is basically learning a new task. This process allows us to quickly achieve state of the art results without having to design and train our own model from scratch. However, it may happen that a much smaller and simpler model would also perform well on our dataset. With model pruning we identify the importance of weights during training and remove the weights that are contributing very little to the learning process. We can do this in an iterative way where we remove a small percentage of weights in each iteration. Removing means to eliminate the entries in the tensor so its size shrinks.\n",
    "\n",
    "We use SageMaker Debugger to get weights, activation outputs and gradients during training. These tensors are used to compute the importance of weights. We will use SageMaker Experiments to keep track of each pruning iteration: if we prune too much we may degrade model accuracy, so we will monitor number of parameters versus validation accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install sagemaker\n",
    "! pip -q install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get the [Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) dataset. This dataset consists of 101 image categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 101_ObjectCategories.tar.gz ...\n",
      "Data extracted.\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import requests\n",
    "import os\n",
    "\n",
    "filename = '101_ObjectCategories.tar.gz'\n",
    "data_url = os.path.join(\"https://s3.us-east-2.amazonaws.com/mxnet-public\", filename)\n",
    "\n",
    "r = requests.get(data_url, stream=True)\n",
    "with open(filename, 'wb') as f:\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "        if chunk: \n",
    "            f.write(chunk)\n",
    "\n",
    "print('Extracting {} ...'.format(filename))\n",
    "tar = tarfile.open(filename, \"r:gz\")\n",
    "tar.extractall('.')\n",
    "tar.close()\n",
    "print('Data extracted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And upload it to our SageMaker default bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload files from101_ObjectCategories to sagemaker-us-east-2-005166108777\n",
      "101_ObjectCategories\n",
      "101_ObjectCategories/tick\n",
      "101_ObjectCategories/garfield\n",
      "101_ObjectCategories/airplanes\n",
      "101_ObjectCategories/bonsai\n",
      "101_ObjectCategories/hedgehog\n",
      "101_ObjectCategories/butterfly\n",
      "101_ObjectCategories/elephant\n",
      "101_ObjectCategories/lobster\n",
      "101_ObjectCategories/Leopards\n",
      "101_ObjectCategories/saxophone\n",
      "101_ObjectCategories/Faces_easy\n",
      "101_ObjectCategories/grand_piano\n",
      "101_ObjectCategories/dragonfly\n",
      "101_ObjectCategories/anchor\n",
      "101_ObjectCategories/menorah\n",
      "101_ObjectCategories/octopus\n",
      "101_ObjectCategories/inline_skate\n",
      "101_ObjectCategories/headphone\n",
      "101_ObjectCategories/laptop\n",
      "101_ObjectCategories/pizza\n",
      "101_ObjectCategories/windsor_chair\n",
      "101_ObjectCategories/wild_cat\n",
      "101_ObjectCategories/hawksbill\n",
      "101_ObjectCategories/Motorbikes\n",
      "101_ObjectCategories/wheelchair\n",
      "101_ObjectCategories/revolver\n",
      "101_ObjectCategories/buddha\n",
      "101_ObjectCategories/joshua_tree\n",
      "101_ObjectCategories/camera\n",
      "101_ObjectCategories/pyramid\n",
      "101_ObjectCategories/crab\n",
      "101_ObjectCategories/accordion\n",
      "101_ObjectCategories/kangaroo\n",
      "101_ObjectCategories/brain\n",
      "101_ObjectCategories/scorpion\n",
      "101_ObjectCategories/flamingo\n",
      "101_ObjectCategories/car_side\n",
      "101_ObjectCategories/schooner\n",
      "101_ObjectCategories/euphonium\n",
      "101_ObjectCategories/crayfish\n",
      "101_ObjectCategories/yin_yang\n",
      "101_ObjectCategories/Faces\n",
      "101_ObjectCategories/pagoda\n",
      "101_ObjectCategories/rooster\n",
      "101_ObjectCategories/umbrella\n",
      "101_ObjectCategories/cellphone\n",
      "101_ObjectCategories/sunflower\n",
      "101_ObjectCategories/ceiling_fan\n",
      "101_ObjectCategories/dalmatian\n",
      "101_ObjectCategories/helicopter\n",
      "101_ObjectCategories/barrel\n",
      "101_ObjectCategories/crocodile_head\n",
      "101_ObjectCategories/gerenuk\n",
      "101_ObjectCategories/ibis\n",
      "101_ObjectCategories/beaver\n",
      "101_ObjectCategories/pigeon\n",
      "101_ObjectCategories/ketch\n",
      "101_ObjectCategories/ant\n",
      "101_ObjectCategories/gramophone\n",
      "101_ObjectCategories/nautilus\n",
      "101_ObjectCategories/brontosaurus\n",
      "101_ObjectCategories/starfish\n",
      "101_ObjectCategories/binocular\n",
      "101_ObjectCategories/stop_sign\n",
      "101_ObjectCategories/dollar_bill\n",
      "101_ObjectCategories/dolphin\n",
      "101_ObjectCategories/rhino\n",
      "101_ObjectCategories/cannon\n",
      "101_ObjectCategories/snoopy\n",
      "101_ObjectCategories/bass\n",
      "101_ObjectCategories/electric_guitar\n",
      "101_ObjectCategories/flamingo_head\n",
      "101_ObjectCategories/trilobite\n",
      "101_ObjectCategories/platypus\n",
      "101_ObjectCategories/stegosaurus\n",
      "101_ObjectCategories/cup\n",
      "101_ObjectCategories/cougar_body\n",
      "101_ObjectCategories/wrench\n",
      "101_ObjectCategories/metronome\n",
      "101_ObjectCategories/llama\n",
      "101_ObjectCategories/sea_horse\n",
      "101_ObjectCategories/crocodile\n",
      "101_ObjectCategories/soccer_ball\n",
      "101_ObjectCategories/minaret\n",
      "101_ObjectCategories/mandolin\n",
      "101_ObjectCategories/emu\n",
      "101_ObjectCategories/water_lilly\n",
      "101_ObjectCategories/lotus\n",
      "101_ObjectCategories/lamp\n",
      "101_ObjectCategories/ewer\n",
      "101_ObjectCategories/okapi\n",
      "101_ObjectCategories/chair\n",
      "101_ObjectCategories/chandelier\n",
      "101_ObjectCategories/stapler\n",
      "101_ObjectCategories/scissors\n",
      "101_ObjectCategories/panda\n",
      "101_ObjectCategories/strawberry\n",
      "101_ObjectCategories/cougar_face\n",
      "101_ObjectCategories/ferry\n",
      "101_ObjectCategories/mayfly\n",
      "101_ObjectCategories/watch\n",
      "Upload files from101_ObjectCategories_test to sagemaker-us-east-2-005166108777\n",
      "101_ObjectCategories_test\n",
      "101_ObjectCategories_test/tick\n",
      "101_ObjectCategories_test/garfield\n",
      "101_ObjectCategories_test/airplanes\n",
      "101_ObjectCategories_test/bonsai\n",
      "101_ObjectCategories_test/hedgehog\n",
      "101_ObjectCategories_test/butterfly\n",
      "101_ObjectCategories_test/elephant\n",
      "101_ObjectCategories_test/lobster\n",
      "101_ObjectCategories_test/Leopards\n",
      "101_ObjectCategories_test/saxophone\n",
      "101_ObjectCategories_test/Faces_easy\n",
      "101_ObjectCategories_test/grand_piano\n",
      "101_ObjectCategories_test/dragonfly\n",
      "101_ObjectCategories_test/anchor\n",
      "101_ObjectCategories_test/menorah\n",
      "101_ObjectCategories_test/octopus\n",
      "101_ObjectCategories_test/inline_skate\n",
      "101_ObjectCategories_test/headphone\n",
      "101_ObjectCategories_test/laptop\n",
      "101_ObjectCategories_test/pizza\n",
      "101_ObjectCategories_test/windsor_chair\n",
      "101_ObjectCategories_test/wild_cat\n",
      "101_ObjectCategories_test/hawksbill\n",
      "101_ObjectCategories_test/Motorbikes\n",
      "101_ObjectCategories_test/wheelchair\n",
      "101_ObjectCategories_test/revolver\n",
      "101_ObjectCategories_test/buddha\n",
      "101_ObjectCategories_test/joshua_tree\n",
      "101_ObjectCategories_test/camera\n",
      "101_ObjectCategories_test/pyramid\n",
      "101_ObjectCategories_test/crab\n",
      "101_ObjectCategories_test/accordion\n",
      "101_ObjectCategories_test/kangaroo\n",
      "101_ObjectCategories_test/brain\n",
      "101_ObjectCategories_test/scorpion\n",
      "101_ObjectCategories_test/flamingo\n",
      "101_ObjectCategories_test/car_side\n",
      "101_ObjectCategories_test/schooner\n",
      "101_ObjectCategories_test/euphonium\n",
      "101_ObjectCategories_test/crayfish\n",
      "101_ObjectCategories_test/yin_yang\n",
      "101_ObjectCategories_test/Faces\n",
      "101_ObjectCategories_test/pagoda\n",
      "101_ObjectCategories_test/rooster\n",
      "101_ObjectCategories_test/umbrella\n",
      "101_ObjectCategories_test/cellphone\n",
      "101_ObjectCategories_test/sunflower\n",
      "101_ObjectCategories_test/ceiling_fan\n",
      "101_ObjectCategories_test/dalmatian\n",
      "101_ObjectCategories_test/helicopter\n",
      "101_ObjectCategories_test/barrel\n",
      "101_ObjectCategories_test/crocodile_head\n",
      "101_ObjectCategories_test/gerenuk\n",
      "101_ObjectCategories_test/ibis\n",
      "101_ObjectCategories_test/beaver\n",
      "101_ObjectCategories_test/pigeon\n",
      "101_ObjectCategories_test/ketch\n",
      "101_ObjectCategories_test/ant\n",
      "101_ObjectCategories_test/gramophone\n",
      "101_ObjectCategories_test/nautilus\n",
      "101_ObjectCategories_test/brontosaurus\n",
      "101_ObjectCategories_test/starfish\n",
      "101_ObjectCategories_test/binocular\n",
      "101_ObjectCategories_test/stop_sign\n",
      "101_ObjectCategories_test/dollar_bill\n",
      "101_ObjectCategories_test/dolphin\n",
      "101_ObjectCategories_test/rhino\n",
      "101_ObjectCategories_test/cannon\n",
      "101_ObjectCategories_test/snoopy\n",
      "101_ObjectCategories_test/bass\n",
      "101_ObjectCategories_test/electric_guitar\n",
      "101_ObjectCategories_test/flamingo_head\n",
      "101_ObjectCategories_test/trilobite\n",
      "101_ObjectCategories_test/platypus\n",
      "101_ObjectCategories_test/stegosaurus\n",
      "101_ObjectCategories_test/cup\n",
      "101_ObjectCategories_test/cougar_body\n",
      "101_ObjectCategories_test/wrench\n",
      "101_ObjectCategories_test/metronome\n",
      "101_ObjectCategories_test/llama\n",
      "101_ObjectCategories_test/sea_horse\n",
      "101_ObjectCategories_test/crocodile\n",
      "101_ObjectCategories_test/soccer_ball\n",
      "101_ObjectCategories_test/minaret\n",
      "101_ObjectCategories_test/mandolin\n",
      "101_ObjectCategories_test/emu\n",
      "101_ObjectCategories_test/water_lilly\n",
      "101_ObjectCategories_test/lotus\n",
      "101_ObjectCategories_test/lamp\n",
      "101_ObjectCategories_test/ewer\n",
      "101_ObjectCategories_test/okapi\n",
      "101_ObjectCategories_test/chair\n",
      "101_ObjectCategories_test/chandelier\n",
      "101_ObjectCategories_test/stapler\n",
      "101_ObjectCategories_test/scissors\n",
      "101_ObjectCategories_test/panda\n",
      "101_ObjectCategories_test/strawberry\n",
      "101_ObjectCategories_test/cougar_face\n",
      "101_ObjectCategories_test/ferry\n",
      "101_ObjectCategories_test/mayfly\n",
      "101_ObjectCategories_test/watch\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "def upload_to_s3(path, directory_name, bucket, counter=-1):\n",
    "    \n",
    "    print(\"Upload files from\" + path + \" to \" + bucket)\n",
    "    client = boto3.client('s3')\n",
    "    \n",
    "    for path, subdirs, files in os.walk(path):\n",
    "        path = path.replace(\"\\\\\",\"/\")\n",
    "        print(path)\n",
    "        for file in files[0:counter]:\n",
    "            client.upload_file(os.path.join(path, file), bucket, directory_name+'/'+path.split(\"/\")[-1]+'/'+file)\n",
    "            \n",
    "boto_session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "upload_to_s3(\"101_ObjectCategories\", directory_name=\"101_ObjectCategories_train\",  bucket=bucket)\n",
    "\n",
    "#we will compute saliency maps for all images in the test dataset, so we will only upload 4 images \n",
    "upload_to_s3(\"101_ObjectCategories_test\", directory_name=\"101_ObjectCategories_test\", bucket=bucket, counter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and save ResNet model\n",
    "\n",
    "First we load a pre-trained [ResNet](https://arxiv.org/abs/1512.03385) model from PyTorch model zoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the last Linear layer outputs 1000 values, which is the number of classes the model has originally been trained on. Here, we will fine-tune the model on the Caltech101 dataset: as it has only 101 classes, we need to set the number of output classes to 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeatures = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(nfeatures, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we store the model definition and weights in an output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': model,\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'src/model_checkpoint')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell creates a SageMaker experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experiment(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fd3d1014e48>,experiment_name='02-05-2020-19-31-33-model-pruning-experiment',description='Iterative model pruning of ResNet trained on Caltech101',experiment_arn='arn:aws:sagemaker:us-east-2:005166108777:experiment/02-05-2020-19-31-33-model-pruning-experiment',response_metadata={'RequestId': '2bb37cd7-2487-4130-ac2b-1379efe77fbe', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2bb37cd7-2487-4130-ac2b-1379efe77fbe', 'content-type': 'application/x-amz-json-1.1', 'content-length': '116', 'date': 'Sat, 02 May 2020 19:31:33 GMT'}, 'RetryAttempts': 0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "sagemaker_boto_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "#name of experiment\n",
    "timestep = datetime.now()\n",
    "timestep = timestep.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "experiment_name = timestep + \"-model-pruning-experiment\"\n",
    "\n",
    "#create experiment\n",
    "Experiment.create(\n",
    "    experiment_name=experiment_name, \n",
    "    description=\"Iterative model pruning of ResNet trained on Caltech101\", \n",
    "    sagemaker_boto_client=sagemaker_boto_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell defines a list of tensor names that be used to compute filter ranks. The lists are defined in the Python script `model_resnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smdebug in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.7.2)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (1.12.47)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (1.18.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from smdebug) (3.11.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->smdebug) (1.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->smdebug) (2.2.0)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.15.47)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.3.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (39.1.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.47->boto3>=1.10.32->smdebug) (0.14)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.47->boto3>=1.10.32->smdebug) (1.23)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.47->boto3>=1.10.32->smdebug) (2.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_resnet\n",
    "\n",
    "activation_outputs = model_resnet.activation_outputs\n",
    "gradients = model_resnet.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative model pruning: step by step\n",
    "\n",
    "Before we jump into the code for running the iterative model pruning we will walk through the code step by step. \n",
    "\n",
    "#### Step 0: Create trial and debugger hook coonfiguration\n",
    "First we create a new trial for each pruning iteration. That allows us to track our training jobs and see which models have the lowest number of parameters and best accuracy. We use the `smexperiments` library to create a trial within our experiment.                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.trial import Trial\n",
    "\n",
    "trial = Trial.create(\n",
    "        experiment_name=experiment_name,\n",
    "        sagemaker_boto_client=sagemaker_boto_client\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the experiment_config which is a dictionary that will be passed to the SageMaker training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = { \"ExperimentName\": experiment_name, \n",
    "                      \"TrialName\":  trial.trial_name,\n",
    "                      \"TrialComponentDisplayName\": \"Training\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a debugger hook configuration to define a custom collection of tensors to be emitted. The custom collection contains all weights and biases of the model. It also includes individual layer outputs and their gradients which will be used to compute filter ranks. Tensors are saved every 100th iteration where an iteration represents one forward and backward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "      collection_configs=[ \n",
    "          CollectionConfig(\n",
    "                name=\"custom_collection\",\n",
    "                parameters={ \"include_regex\": \".*relu|.*weight|.*bias|.*running_mean|.*running_var|.*CrossEntropyLoss\",\n",
    "                             \"save_interval\": \"100\" })])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Start training job\n",
    "Now we define the SageMaker PyTorch Estimator. We will train the model on an `ml.p2.xlarge` instance. The model definition plus training code is defined in the entry_point file `train.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(role=sagemaker.get_execution_role(),\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.p2.xlarge',\n",
    "                  train_volume_size=400,\n",
    "                  source_dir='src',\n",
    "                  entry_point='train.py',\n",
    "                  framework_version='1.3.1',\n",
    "                  py_version='py3',\n",
    "                  metric_definitions=[ {'Name':'train:loss', 'Regex':'loss:(.*?)'}, {'Name':'eval:acc', 'Regex':'acc:(.*?)'} ],\n",
    "                  enable_sagemaker_metrics=True,\n",
    "                  hyperparameters = {'epochs': 10},\n",
    "                  debugger_hook_config=debugger_hook_config\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have defined the estimator object we can call `fit` which creates a ml.p2.xlarge instance on which it starts the training. We pass the experiment_config which associates the training job with a trial and an experiment. If we don't specify an `experiment_config` the training job will appear in SageMaker Experiments under `Unassigned trial components`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-19-31-36-075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 19:31:39 Starting - Starting the training job...\n",
      "2020-05-02 19:31:41 Starting - Launching requested ML instances...\n",
      "2020-05-02 19:32:39 Starting - Preparing the instances for training............\n",
      "2020-05-02 19:34:17 Downloading - Downloading input data......\n",
      "2020-05-02 19:35:25 Training - Downloading the training image...........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:17,613 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:17,642 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:20,654 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:21,697 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:21,697 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:21,697 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:21,698 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpe5ohbqps/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\n",
      "2020-05-02 19:37:16 Training - Training image download completed. Training in progress.\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=41761314 sha256=83a2124fa7f6f0fb0272c62081af10e8777d106ac334fc8ff0748307072e139d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4xwkswwp/wheels/64/08/9b/17d876dfe8d96fc4ce74a98f4b79dd2db93e5a255087de5c0e\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 19:37:29,364 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-19-31-36-075\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-19-31-36-075/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-19-31-36-075/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-19-31-36-075\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-19-31-36-075/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 19:37:31.459 algo-1:53 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 19:37:31.460 algo-1:53 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 19:37:31.460 algo-1:53 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 19:37:34.350 algo-1:53 INFO hook.py:326] Monitoring the collections: custom_collection, losses\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:3.2926\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.2612\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:2.2309\u001b[0m\n",
      "\u001b[34macc:0.4627\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:1.6417\u001b[0m\n",
      "\u001b[34macc:0.5846\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:1.2723\u001b[0m\n",
      "\u001b[34macc:0.6791\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:1.0454\u001b[0m\n",
      "\u001b[34macc:0.7214\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.8888\u001b[0m\n",
      "\u001b[34macc:0.7687\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.7829\u001b[0m\n",
      "\u001b[34macc:0.8159\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.7118\u001b[0m\n",
      "\u001b[34macc:0.8234\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.6554\u001b[0m\n",
      "\u001b[34macc:0.8408\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.5908\u001b[0m\n",
      "\u001b[34macc:0.8483\u001b[0m\n",
      "\u001b[34m[2020-05-02 19:47:24.164 algo-1:53 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 19:47:24,516 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 19:47:34 Uploading - Uploading generated training model\n",
      "2020-05-02 19:47:34 Completed - Training job completed\n",
      "Training seconds: 797\n",
      "Billable seconds: 797\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs={'train': 's3://{}/101_ObjectCategories_train'.format(bucket), \n",
    "                      'test': 's3://{}/101_ObjectCategories_test'.format(bucket)}, \n",
    "              experiment_config=experiment_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Get gradients, weights, biases\n",
    "\n",
    "Once the training job has finished, we will retrieve its tensors, such as gradients, weights and biases. We use the `smdebug` library which provides functions to read and filter tensors. First we create a [trial](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md#Trial) that is reading the tensors from S3. \n",
    "\n",
    "For clarification: in the context of SageMaker Debugger a trial is an object that lets you query tensors for a given training job. In the context of SageMaker Experiments a trial is part of an experiment and it presents a collection of training steps involved in a single training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%bash\\nunameOut=\"$(uname -s)\"\\ncase \"${unameOut}\" in\\n    Linux*)     machine=Linux;;\\n    Darwin*)    machine=Mac;;\\nesac\\nif [ \"$machine\" = \"Mac\" ] ; then\\n    PROTOC_ZIP=protoc-3.7.1-osx-x86_64.zip\\n    brew install unzip\\n    echo \"1\"\\nelse\\n    PROTOC_ZIP=protoc-3.7.1-linux-x86_64.zip\\n    echo \"2\"\\n    #apt-get install sudo\\n    #pip install unzip\\nfi\\ncurl -OL https://github.com/google/protobuf/releases/download/v3.7.1/$PROTOC_ZIP\\nsudo unzip -o $PROTOC_ZIP -d /usr/local bin/protoc\\nsudo unzip -o $PROTOC_ZIP -d /usr/local include/*\\nrm -f $PROTOC_ZIP\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%bash\n",
    "unameOut=\"$(uname -s)\"\n",
    "case \"${unameOut}\" in\n",
    "    Linux*)     machine=Linux;;\n",
    "    Darwin*)    machine=Mac;;\n",
    "esac\n",
    "if [ \"$machine\" = \"Mac\" ] ; then\n",
    "    PROTOC_ZIP=protoc-3.7.1-osx-x86_64.zip\n",
    "    brew install unzip\n",
    "    echo \"1\"\n",
    "else\n",
    "    PROTOC_ZIP=protoc-3.7.1-linux-x86_64.zip\n",
    "    echo \"2\"\n",
    "    #apt-get install sudo\n",
    "    #pip install unzip\n",
    "fi\n",
    "curl -OL https://github.com/google/protobuf/releases/download/v3.7.1/$PROTOC_ZIP\n",
    "sudo unzip -o $PROTOC_ZIP -d /usr/local bin/protoc\n",
    "sudo unzip -o $PROTOC_ZIP -d /usr/local include/*\n",
    "rm -f $PROTOC_ZIP\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protobuf==3.11.2\n",
      "protobuf-compiler==1.0.20\n",
      "protobuf3-to-dict==0.1.5\n",
      "libprotoc 3.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep proto\n",
    "!protoc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the next cell run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-19-31-36-075/debug-output\n",
      "[2020-05-02 19:47:58.813 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-19-31-36-075/debug-output\n"
     ]
    }
   ],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "print(path)\n",
    "smdebug_trial = create_trial(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access tensor values, we only need to call `smdebug_trial.tensor()`. For instance to get the outputs of the first ReLU activation at step 0 we run  `smdebug_trial.tensor('layer4.1.relu_0_output_0').value(0, mode=modes.TRAIN)`. Next we compute a filter rank for the convolutions. \n",
    "\n",
    "Some defintions: a filter is a collection of kernels (one kernel for every single input channel) and a filter produces one feature map (output channel). In the image below the convolution creates 64 feature maps (output channels) and uses a kernel of 5x5. By pruning a filter, an entire feature map will be removed. So in the example image below the number of feature maps (output channels) would shrink to 63 and the number of learnable parameters (weights) would be reduced by 1x5x5.\n",
    "\n",
    "![](images/convolution.png) \n",
    "\n",
    "\n",
    "#### Step 3: Compute filter ranks\n",
    "\n",
    "In this notebook we compute filter ranks as described in the article [\"Pruning Convolutional Neural Networks for Resource Efficient Inference\"](https://arxiv.org/pdf/1611.06440.pdf) We basically identify filters that are less important for the final prediction of the model. The product of weights and gradients can be seen as a measure of importance. The product has the dimension `(batch_size, out_channels, width, height)` and we get the average over `axis=0,2,3` to have a single value (rank) for each filter.\n",
    "\n",
    "In the following code we retrieve activation outputs and gradients and compute the filter rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-05-02 20:13:58.222 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 20:13:59.241 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from smdebug import modes\n",
    "\n",
    "def compute_filter_ranks(smdebug_trial, activation_outputs, gradients):\n",
    "    filters = {}\n",
    "    for activation_output_name, gradient_name in zip(activation_outputs, gradients):\n",
    "        for step in smdebug_trial.steps(mode=modes.TRAIN):\n",
    "            \n",
    "            activation_output = smdebug_trial.tensor(activation_output_name).value(step, mode=modes.TRAIN)\n",
    "            gradient = smdebug_trial.tensor(gradient_name).value(step, mode=modes.TRAIN)\n",
    "            rank = activation_output * gradient\n",
    "            rank = np.mean(rank, axis=(0,2,3))\n",
    "\n",
    "            if activation_output_name not in filters:\n",
    "                filters[activation_output_name] = 0\n",
    "            filters[activation_output_name] += rank\n",
    "    return filters\n",
    "\n",
    "filters = compute_filter_ranks(smdebug_trial, activation_outputs, gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we normalize the filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_filter_ranks(filters):\n",
    "    for activation_output_name in filters:\n",
    "        rank = np.abs(filters[activation_output_name])\n",
    "        rank = rank / np.sqrt(np.sum(rank * rank))\n",
    "        filters[activation_output_name] = rank\n",
    "    return filters\n",
    "\n",
    "filters = normalize_filter_ranks(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of filters, sort it by rank and retrieve the smallest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 100 smallest filters [('layer3.1.relu_0_output_0', 78, 1.5483498e-05), ('layer2.1.relu_0_output_0', 11, 4.0021172e-05), ('layer4.1.relu_0_output_0', 273, 5.297476e-05), ('layer4.0.relu_0_output_0', 170, 0.00013654676), ('layer4.1.relu_0_output_0', 208, 0.00017223414), ('layer4.0.relu_0_output_0', 300, 0.00017899263), ('layer4.0.relu_0_output_0', 73, 0.00018451516), ('layer4.1.relu_0_output_0', 304, 0.00022502147), ('layer4.1.relu_0_output_0', 34, 0.00025934185), ('layer4.0.relu_0_output_0', 118, 0.00026283372), ('layer4.1.relu_0_output_0', 255, 0.00027957495), ('layer4.1.relu_0_output_0', 192, 0.00032759082), ('layer4.0.relu_0_output_0', 152, 0.0003959918), ('layer2.1.relu_0_output_0', 111, 0.0004314011), ('layer3.1.relu_0_output_0', 46, 0.0004343964), ('layer2.0.relu_0_output_0', 125, 0.0004375938), ('layer4.1.relu_0_output_0', 382, 0.00048023413), ('layer2.1.relu_0_output_0', 101, 0.0005084389), ('layer4.0.relu_0_output_0', 288, 0.00052248844), ('layer4.0.relu_0_output_0', 276, 0.0005391328), ('layer4.0.relu_0_output_0', 306, 0.00055153994), ('layer3.0.relu_0_output_0', 199, 0.0005630629), ('layer2.0.relu_0_output_0', 6, 0.00058723876), ('layer4.1.relu_0_output_0', 234, 0.00059991615), ('layer4.0.relu_0_output_0', 322, 0.0006411105), ('layer4.1.relu_0_output_0', 474, 0.00071987475), ('layer4.1.relu_0_output_0', 188, 0.0007204898), ('layer3.1.relu_0_output_0', 45, 0.0007308049), ('layer4.0.relu_0_output_0', 173, 0.00075170194), ('layer4.1.relu_0_output_0', 39, 0.0007773252), ('layer4.1.relu_0_output_0', 303, 0.00078238675), ('layer3.1.relu_0_output_0', 14, 0.0008224146), ('layer3.1.relu_0_output_0', 213, 0.00086525915), ('layer3.1.relu_0_output_0', 225, 0.00089640333), ('layer4.0.relu_0_output_0', 88, 0.0009306574), ('layer4.0.relu_0_output_0', 251, 0.0009464525), ('layer4.0.relu_0_output_0', 28, 0.0009593851), ('layer4.1.relu_0_output_0', 27, 0.00096068176), ('layer4.1.relu_0_output_0', 55, 0.0009747066), ('layer3.1.relu_0_output_0', 34, 0.0009780985), ('layer3.0.relu_0_output_0', 89, 0.0010154705), ('layer4.0.relu_0_output_0', 268, 0.0010457708), ('layer3.1.relu_0_output_0', 229, 0.0010501058), ('layer3.1.relu_0_output_0', 212, 0.0010645838), ('layer4.1.relu_0_output_0', 122, 0.001108217), ('layer4.1.relu_0_output_0', 87, 0.0011175589), ('layer4.0.relu_0_output_0', 402, 0.0011263031), ('layer4.0.relu_0_output_0', 160, 0.001137236), ('layer4.0.relu_0_output_0', 327, 0.001175395), ('layer4.0.relu_0_output_0', 232, 0.0012271609), ('layer4.1.relu_0_output_0', 498, 0.0012804919), ('layer3.0.relu_0_output_0', 106, 0.0014178806), ('layer4.0.relu_0_output_0', 112, 0.0014516719), ('layer1.0.relu_0_output_0', 16, 0.0014835012), ('layer4.1.relu_0_output_0', 85, 0.0014957039), ('layer4.0.relu_0_output_0', 187, 0.001521009), ('layer3.1.relu_0_output_0', 36, 0.0015235203), ('layer4.1.relu_0_output_0', 257, 0.0015582967), ('layer4.0.relu_0_output_0', 110, 0.0016175106), ('layer4.1.relu_0_output_0', 404, 0.0016189766), ('layer4.0.relu_0_output_0', 488, 0.0016426687), ('layer4.1.relu_0_output_0', 60, 0.0016634676), ('layer3.0.relu_0_output_0', 193, 0.001688494), ('layer4.0.relu_0_output_0', 455, 0.0017588676), ('layer4.0.relu_0_output_0', 279, 0.0017954718), ('layer2.0.relu_0_output_0', 31, 0.0018455678), ('layer3.0.relu_0_output_0', 72, 0.0018564817), ('layer3.0.relu_0_output_0', 131, 0.0018834369), ('layer4.1.relu_0_output_0', 58, 0.001900316), ('layer4.1.relu_0_output_0', 484, 0.0019067329), ('layer4.1.relu_0_output_0', 429, 0.0019170895), ('layer4.1.relu_0_output_0', 22, 0.0019499032), ('layer4.1.relu_0_output_0', 488, 0.0019716753), ('layer4.0.relu_0_output_0', 249, 0.0019904044), ('layer4.1.relu_0_output_0', 262, 0.0019994602), ('layer2.1.relu_0_output_0', 72, 0.0020336397), ('layer4.0.relu_0_output_0', 114, 0.002051307), ('layer4.1.relu_0_output_0', 89, 0.0020531463), ('layer4.0.relu_0_output_0', 144, 0.0020638555), ('layer4.0.relu_0_output_0', 48, 0.0020819083), ('layer4.0.relu_0_output_0', 361, 0.0020956243), ('layer4.1.relu_0_output_0', 453, 0.0021313403), ('layer4.1.relu_0_output_0', 375, 0.0021965657), ('layer4.1.relu_0_output_0', 366, 0.0022022133), ('layer4.1.relu_0_output_0', 507, 0.002244911), ('layer4.0.relu_0_output_0', 247, 0.0022699158), ('layer4.0.relu_0_output_0', 116, 0.0023298182), ('layer4.0.relu_0_output_0', 56, 0.0023529674), ('layer4.0.relu_0_output_0', 304, 0.00236728), ('layer4.1.relu_0_output_0', 169, 0.0024057839), ('layer4.1.relu_0_output_0', 246, 0.0024264234), ('layer4.0.relu_0_output_0', 137, 0.0024724423), ('layer3.1.relu_0_output_0', 134, 0.0024766582), ('layer3.0.relu_0_output_0', 35, 0.0024989238), ('layer4.0.relu_0_output_0', 194, 0.0025093656), ('layer2.1.relu_0_output_0', 27, 0.0025666908), ('layer4.0.relu_0_output_0', 301, 0.002601976), ('layer4.0.relu_0_output_0', 82, 0.0026339756), ('layer4.1.relu_0_output_0', 433, 0.0026816481), ('layer4.0.relu_0_output_0', 353, 0.0026980378)]\n"
     ]
    }
   ],
   "source": [
    "def get_smallest_filters(filters, n):\n",
    "    filters_list = []\n",
    "    for layer_name in sorted(filters.keys()):\n",
    "        for channel in range(filters[layer_name].shape[0]): \n",
    "            filters_list.append((layer_name, channel, filters[layer_name][channel], ))\n",
    "\n",
    "    filters_list.sort(key = lambda x: x[2])\n",
    "    filters_list = filters_list[:n]\n",
    "    print(\"The\", n, \"smallest filters\", filters_list)\n",
    "    \n",
    "    return filters_list\n",
    "\n",
    "filters_list = get_smallest_filters(filters, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 and step 5: Prune low ranking filters and set new weights\n",
    "\n",
    "Next we prune the model, where we remove filters and their corresponding weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce output channels for conv layer layer1.0. from 64 to 63\n",
      "Reduce bn layer layer1.0. from 64 to 63\n",
      "Reduce output channels for conv layer layer2.0. from 128 to 125\n",
      "Reduce bn layer layer2.0. from 128 to 125\n",
      "Reduce output channels for conv layer layer2.1. from 128 to 123\n",
      "Reduce bn layer layer2.1. from 128 to 123\n",
      "Reduce output channels for conv layer layer3.0. from 256 to 249\n",
      "Reduce bn layer layer3.0. from 256 to 249\n",
      "Reduce output channels for conv layer layer3.1. from 256 to 245\n",
      "Reduce bn layer layer3.1. from 256 to 245\n",
      "Reduce output channels for conv layer layer4.0. from 512 to 474\n",
      "Reduce bn layer layer4.0. from 512 to 474\n",
      "Reduce output channels for conv layer layer4.1. from 512 to 477\n",
      "Reduce bn layer layer4.1. from 512 to 477\n"
     ]
    }
   ],
   "source": [
    "step = smdebug_trial.steps(mode=modes.TRAIN)[-1]\n",
    "\n",
    "model = model_resnet.prune(model,  \n",
    "                    filters_list, \n",
    "                    smdebug_trial, \n",
    "                    step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Start next pruning iteration\n",
    "Once we have pruned the model, the new architecture and pruned weights will be saved under src and will be used by the next training job in the next pruning iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pruned model\n",
    "checkpoint = {'model': model,\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'src/model_checkpoint')\n",
    "\n",
    "#clean up\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall workflow\n",
    "The overall workflow looks like the following:\n",
    " ![](images/workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run iterative model pruning\n",
    "\n",
    "After having gone through the code step by step, we are ready to run the full worfklow. The following cell runs 10 pruning iterations: in each iteration of the pruning a new SageMaker training job is started, where it emits gradients and activation outputs to Amazon S3. Once the job has finished, filter ranks are computed and the 100 smallest filters are removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new trial Trial-2020-05-02-202227-bcvd for pruning step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-20-22-27-327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 20:22:30 Starting - Starting the training job...\n",
      "2020-05-02 20:22:32 Starting - Launching requested ML instances...\n",
      "2020-05-02 20:23:30 Starting - Preparing the instances for training.........\n",
      "2020-05-02 20:24:54 Downloading - Downloading input data......\n",
      "2020-05-02 20:25:46 Training - Downloading the training image............\n",
      "2020-05-02 20:27:57 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:58,007 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:58,033 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:58,321 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:59,230 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:59,230 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:59,231 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 20:27:59,231 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpw4fd_lsc/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=39242760 sha256=486503283d68e1c16c6b0413784b9406e73590cd3a80394f741eae38006fbd27\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0oh73q7u/wheels/34/7e/d4/aa3035710310b737885b33544490a8fb906721c17917dfbbd1\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:28:05,762 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-20-22-27-327\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-22-27-327/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-22-27-327/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-20-22-27-327\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-22-27-327/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:28:08.333 algo-1:52 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:28:08.334 algo-1:52 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:28:08.334 algo-1:52 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:28:10.729 algo-1:52 INFO hook.py:326] Monitoring the collections: custom_collection, losses\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.6428\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8433\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.5759\u001b[0m\n",
      "\u001b[34macc:0.8483\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.5318\u001b[0m\n",
      "\u001b[34macc:0.8557\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.5067\u001b[0m\n",
      "\u001b[34macc:0.8507\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.4876\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.4650\u001b[0m\n",
      "\u001b[34macc:0.8607\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.4405\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.4201\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.4077\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.3854\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:37:30.071 algo-1:52 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:37:30,371 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 20:38:03 Uploading - Uploading generated training model\n",
      "2020-05-02 20:38:11 Completed - Training job completed\n",
      "Training seconds: 797\n",
      "Billable seconds: 797\n",
      "Training job pytorch-training-2020-05-02-20-22-27-327  finished.\n",
      "[2020-05-02 20:38:49.798 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-22-27-327/debug-output\n",
      "[2020-05-02 20:38:50.256 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 20:38:51.275 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.1.relu_0_output_0', 80, 5.4089327e-05), ('layer3.0.relu_0_output_0', 111, 0.00011155832), ('layer4.1.relu_0_output_0', 230, 0.00011311611), ('layer4.1.relu_0_output_0', 343, 0.00018881852), ('layer4.1.relu_0_output_0', 472, 0.00019570526), ('layer4.1.relu_0_output_0', 176, 0.00023185683), ('layer4.1.relu_0_output_0', 56, 0.00023340294), ('layer4.0.relu_0_output_0', 315, 0.00023370335), ('layer2.0.relu_0_output_0', 120, 0.00025441582), ('layer4.0.relu_0_output_0', 264, 0.0003021626), ('layer3.0.relu_0_output_0', 175, 0.00042332688), ('layer4.0.relu_0_output_0', 465, 0.00042652173), ('layer3.1.relu_0_output_0', 20, 0.00045113207), ('layer4.1.relu_0_output_0', 450, 0.00045633578), ('layer4.1.relu_0_output_0', 244, 0.00047798533), ('layer4.0.relu_0_output_0', 407, 0.00048575373), ('layer4.1.relu_0_output_0', 64, 0.0004941464), ('layer4.1.relu_0_output_0', 155, 0.00050324993), ('layer3.0.relu_0_output_0', 125, 0.0005365694), ('layer4.1.relu_0_output_0', 408, 0.0005500073), ('layer4.1.relu_0_output_0', 19, 0.00055758195), ('layer4.1.relu_0_output_0', 476, 0.0005716636), ('layer4.1.relu_0_output_0', 201, 0.0005948296), ('layer1.1.relu_0_output_0', 56, 0.00059755327), ('layer3.0.relu_0_output_0', 201, 0.000615678), ('layer4.0.relu_0_output_0', 91, 0.00067225227), ('layer4.0.relu_0_output_0', 152, 0.0006862001), ('layer4.1.relu_0_output_0', 272, 0.00073638075), ('layer4.1.relu_0_output_0', 113, 0.000748059), ('layer3.1.relu_0_output_0', 236, 0.0007735933), ('layer4.0.relu_0_output_0', 117, 0.0008014076), ('layer4.1.relu_0_output_0', 41, 0.0009356342), ('layer3.0.relu_0_output_0', 215, 0.0009500546), ('layer3.0.relu_0_output_0', 62, 0.00095074315), ('layer3.0.relu_0_output_0', 113, 0.0010434873), ('layer3.0.relu_0_output_0', 135, 0.001048644), ('layer3.1.relu_0_output_0', 169, 0.001078799), ('layer4.0.relu_0_output_0', 338, 0.0011038132), ('layer2.0.relu_0_output_0', 31, 0.0011322398), ('layer4.1.relu_0_output_0', 298, 0.0011594878), ('layer4.1.relu_0_output_0', 212, 0.0012189986), ('layer4.0.relu_0_output_0', 470, 0.0012208866), ('layer4.1.relu_0_output_0', 45, 0.0012254847), ('layer4.0.relu_0_output_0', 307, 0.0012283878), ('layer4.1.relu_0_output_0', 11, 0.0012293722), ('layer4.1.relu_0_output_0', 332, 0.0012543596), ('layer4.0.relu_0_output_0', 61, 0.0012681994), ('layer4.0.relu_0_output_0', 327, 0.0013268989), ('layer4.1.relu_0_output_0', 17, 0.0013283512), ('layer3.1.relu_0_output_0', 65, 0.0013370622), ('layer4.0.relu_0_output_0', 66, 0.0014279924), ('layer4.1.relu_0_output_0', 397, 0.0014372268), ('layer4.0.relu_0_output_0', 214, 0.0014882263), ('layer3.1.relu_0_output_0', 232, 0.0015635538), ('layer2.1.relu_0_output_0', 42, 0.0016172373), ('layer4.1.relu_0_output_0', 307, 0.0016198392), ('layer4.1.relu_0_output_0', 384, 0.0016257415), ('layer4.1.relu_0_output_0', 138, 0.0016363215), ('layer3.1.relu_0_output_0', 62, 0.0016994044), ('layer4.1.relu_0_output_0', 62, 0.0017171241), ('layer3.0.relu_0_output_0', 88, 0.0017197897), ('layer4.0.relu_0_output_0', 293, 0.0017743708), ('layer4.1.relu_0_output_0', 208, 0.0018138798), ('layer3.1.relu_0_output_0', 164, 0.0018391714), ('layer4.1.relu_0_output_0', 248, 0.0018517134), ('layer4.1.relu_0_output_0', 105, 0.001877652), ('layer3.0.relu_0_output_0', 194, 0.0018881205), ('layer4.1.relu_0_output_0', 381, 0.001911202), ('layer2.1.relu_0_output_0', 60, 0.0020318825), ('layer4.0.relu_0_output_0', 393, 0.0020338094), ('layer4.0.relu_0_output_0', 177, 0.002053422), ('layer3.1.relu_0_output_0', 221, 0.0020728766), ('layer4.0.relu_0_output_0', 322, 0.0021128308), ('layer3.0.relu_0_output_0', 220, 0.0021340563), ('layer4.1.relu_0_output_0', 76, 0.0021898642), ('layer4.0.relu_0_output_0', 86, 0.002206825), ('layer4.1.relu_0_output_0', 456, 0.0022240337), ('layer4.0.relu_0_output_0', 289, 0.0022329707), ('layer3.1.relu_0_output_0', 171, 0.002240567), ('layer2.0.relu_0_output_0', 53, 0.002243467), ('layer2.0.relu_0_output_0', 24, 0.0022441566), ('layer4.1.relu_0_output_0', 438, 0.0022519508), ('layer3.1.relu_0_output_0', 131, 0.0022570058), ('layer3.0.relu_0_output_0', 132, 0.002262848), ('layer4.1.relu_0_output_0', 259, 0.0022810565), ('layer3.1.relu_0_output_0', 67, 0.0022846868), ('layer4.1.relu_0_output_0', 389, 0.0022926733), ('layer4.1.relu_0_output_0', 66, 0.0023013176), ('layer4.0.relu_0_output_0', 81, 0.0023430884), ('layer3.0.relu_0_output_0', 106, 0.0023745818), ('layer4.0.relu_0_output_0', 335, 0.002375053), ('layer3.1.relu_0_output_0', 30, 0.002450169), ('layer4.0.relu_0_output_0', 205, 0.0024718542), ('layer3.0.relu_0_output_0', 96, 0.002482419), ('layer3.0.relu_0_output_0', 143, 0.0024834385), ('layer4.1.relu_0_output_0', 169, 0.0025543072), ('layer4.1.relu_0_output_0', 74, 0.0025546793), ('layer4.1.relu_0_output_0', 382, 0.0025729432), ('layer2.1.relu_0_output_0', 101, 0.0025779745), ('layer4.1.relu_0_output_0', 333, 0.0026909374)]\n",
      "Reduce output channels for conv layer layer1.1. from 64 to 63\n",
      "Reduce bn layer layer1.1. from 64 to 63\n",
      "Reduce output channels for conv layer layer2.0. from 125 to 121\n",
      "Reduce bn layer layer2.0. from 125 to 121\n",
      "Reduce output channels for conv layer layer2.1. from 123 to 120\n",
      "Reduce bn layer layer2.1. from 123 to 120\n",
      "Reduce output channels for conv layer layer3.0. from 249 to 234\n",
      "Reduce bn layer layer3.0. from 249 to 234\n",
      "Reduce output channels for conv layer layer3.1. from 245 to 233\n",
      "Reduce bn layer layer3.1. from 245 to 233\n",
      "Reduce output channels for conv layer layer4.0. from 474 to 451\n",
      "Reduce bn layer layer4.0. from 474 to 451\n",
      "Reduce output channels for conv layer layer4.1. from 477 to 435\n",
      "Reduce bn layer layer4.1. from 477 to 435\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-204041-xdiz for pruning step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-20-40-42-292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 20:40:45 Starting - Starting the training job...\n",
      "2020-05-02 20:40:46 Starting - Launching requested ML instances...\n",
      "2020-05-02 20:41:41 Starting - Preparing the instances for training............\n",
      "2020-05-02 20:43:19 Downloading - Downloading input data......\n",
      "2020-05-02 20:44:34 Training - Downloading the training image...........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:27,632 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:27,661 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:30,714 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:31,663 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:31,663 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:31,663 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:31,664 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpf9g3ai73/module_dir\u001b[0m\n",
      "\n",
      "2020-05-02 20:46:26 Training - Training image download completed. Training in progress.\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=36763977 sha256=d398c2edabb8061d5b2a6ff126b732b47315f4f10f65a3844dbb08cdf8fb9fbd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_mhwoqo/wheels/3c/20/2c/2b71e0dc4567acf126f325a2a294282775b5fb9c3b7213f436\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:46:37,938 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-20-40-42-292\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-40-42-292/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-40-42-292/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-20-40-42-292\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-40-42-292/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:46:39.887 algo-1:52 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:46:39.888 algo-1:52 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:46:39.888 algo-1:52 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:46:42.803 algo-1:52 INFO hook.py:326] Monitoring the collections: custom_collection, losses\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.4413\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8682\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.4105\u001b[0m\n",
      "\u001b[34macc:0.8682\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.3840\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.3866\u001b[0m\n",
      "\u001b[34macc:0.8831\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.3624\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.3772\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.3505\u001b[0m\n",
      "\u001b[34macc:0.8831\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.3261\u001b[0m\n",
      "\u001b[34macc:0.8881\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.3330\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.3272\u001b[0m\n",
      "\u001b[34macc:0.8980\u001b[0m\n",
      "\u001b[34m[2020-05-02 20:56:23.379 algo-1:52 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 20:56:23,749 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 20:56:44 Uploading - Uploading generated training model\n",
      "2020-05-02 20:56:44 Completed - Training job completed\n",
      "Training seconds: 805\n",
      "Billable seconds: 805\n",
      "Training job pytorch-training-2020-05-02-20-40-42-292  finished.\n",
      "[2020-05-02 20:57:03.962 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-40-42-292/debug-output\n",
      "[2020-05-02 20:57:04.534 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 20:57:05.554 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.1.relu_0_output_0', 89, 4.164292e-05), ('layer4.0.relu_0_output_0', 142, 5.364692e-05), ('layer4.1.relu_0_output_0', 357, 5.833186e-05), ('layer4.1.relu_0_output_0', 204, 9.311695e-05), ('layer4.0.relu_0_output_0', 14, 0.00010672734), ('layer2.0.relu_0_output_0', 17, 0.00020764786), ('layer4.1.relu_0_output_0', 313, 0.00024290125), ('layer4.0.relu_0_output_0', 72, 0.00025606848), ('layer3.1.relu_0_output_0', 185, 0.0002669333), ('layer4.1.relu_0_output_0', 44, 0.0002795237), ('layer4.1.relu_0_output_0', 1, 0.00031454914), ('layer4.0.relu_0_output_0', 295, 0.00033030397), ('layer2.0.relu_0_output_0', 90, 0.0003588948), ('layer4.1.relu_0_output_0', 340, 0.00040383334), ('layer2.0.relu_0_output_0', 99, 0.00040685385), ('layer4.1.relu_0_output_0', 287, 0.00041798575), ('layer4.0.relu_0_output_0', 271, 0.00042033446), ('layer4.0.relu_0_output_0', 228, 0.00042418184), ('layer4.1.relu_0_output_0', 115, 0.0004866833), ('layer4.0.relu_0_output_0', 138, 0.0005411295), ('layer3.0.relu_0_output_0', 25, 0.00054189627), ('layer3.0.relu_0_output_0', 58, 0.0005473177), ('layer3.0.relu_0_output_0', 206, 0.0006161816), ('layer4.0.relu_0_output_0', 263, 0.0006580694), ('layer3.1.relu_0_output_0', 49, 0.0006823048), ('layer4.1.relu_0_output_0', 415, 0.0007169585), ('layer4.0.relu_0_output_0', 260, 0.0007558231), ('layer4.1.relu_0_output_0', 298, 0.0007590036), ('layer3.1.relu_0_output_0', 212, 0.0007638209), ('layer4.1.relu_0_output_0', 247, 0.00078165275), ('layer3.1.relu_0_output_0', 88, 0.0007879888), ('layer2.1.relu_0_output_0', 14, 0.00078993174), ('layer3.0.relu_0_output_0', 115, 0.000885712), ('layer4.1.relu_0_output_0', 409, 0.0009282688), ('layer2.0.relu_0_output_0', 7, 0.0009402735), ('layer4.0.relu_0_output_0', 6, 0.00094331184), ('layer4.1.relu_0_output_0', 103, 0.0010518482), ('layer4.1.relu_0_output_0', 56, 0.0010635), ('layer4.0.relu_0_output_0', 213, 0.0010671631), ('layer3.0.relu_0_output_0', 213, 0.0011073339), ('layer3.0.relu_0_output_0', 174, 0.0011207045), ('layer4.1.relu_0_output_0', 57, 0.0011507324), ('layer4.1.relu_0_output_0', 175, 0.0011606299), ('layer4.1.relu_0_output_0', 396, 0.0011709254), ('layer4.1.relu_0_output_0', 256, 0.0012585995), ('layer4.0.relu_0_output_0', 100, 0.0012762904), ('layer4.0.relu_0_output_0', 431, 0.0012765441), ('layer4.0.relu_0_output_0', 166, 0.0013115309), ('layer3.0.relu_0_output_0', 151, 0.0013890358), ('layer3.0.relu_0_output_0', 117, 0.0013976658), ('layer4.1.relu_0_output_0', 272, 0.001417185), ('layer4.1.relu_0_output_0', 162, 0.0014869091), ('layer4.0.relu_0_output_0', 97, 0.0015745657), ('layer4.1.relu_0_output_0', 3, 0.0016177207), ('layer2.0.relu_0_output_0', 38, 0.0016436236), ('layer2.0.relu_0_output_0', 60, 0.0016567719), ('layer4.0.relu_0_output_0', 235, 0.0016814021), ('layer4.0.relu_0_output_0', 416, 0.0016872977), ('layer4.0.relu_0_output_0', 127, 0.0017390781), ('layer3.0.relu_0_output_0', 167, 0.0017406816), ('layer4.1.relu_0_output_0', 250, 0.0017452968), ('layer4.0.relu_0_output_0', 426, 0.001768645), ('layer4.1.relu_0_output_0', 153, 0.0017696137), ('layer4.1.relu_0_output_0', 63, 0.0017944161), ('layer4.1.relu_0_output_0', 121, 0.0017969585), ('layer4.1.relu_0_output_0', 297, 0.0018097201), ('layer4.0.relu_0_output_0', 432, 0.0018379466), ('layer3.1.relu_0_output_0', 10, 0.0018469807), ('layer4.0.relu_0_output_0', 249, 0.0018622191), ('layer4.0.relu_0_output_0', 312, 0.0019297637), ('layer4.0.relu_0_output_0', 117, 0.0019384006), ('layer4.0.relu_0_output_0', 242, 0.0020099399), ('layer3.1.relu_0_output_0', 194, 0.0021281105), ('layer4.1.relu_0_output_0', 402, 0.0021408682), ('layer1.0.relu_0_output_0', 1, 0.0021579626), ('layer4.0.relu_0_output_0', 102, 0.0021715339), ('layer4.1.relu_0_output_0', 335, 0.002216074), ('layer4.1.relu_0_output_0', 302, 0.0022347546), ('layer3.0.relu_0_output_0', 217, 0.0022561955), ('layer4.1.relu_0_output_0', 300, 0.0022716876), ('layer3.0.relu_0_output_0', 92, 0.0023061263), ('layer3.0.relu_0_output_0', 0, 0.0023316774), ('layer3.1.relu_0_output_0', 163, 0.002342755), ('layer3.1.relu_0_output_0', 121, 0.0023604406), ('layer4.1.relu_0_output_0', 102, 0.0023679128), ('layer4.0.relu_0_output_0', 23, 0.0023737827), ('layer3.0.relu_0_output_0', 70, 0.0024086137), ('layer4.0.relu_0_output_0', 110, 0.0024257544), ('layer3.1.relu_0_output_0', 66, 0.0024892837), ('layer4.1.relu_0_output_0', 95, 0.0025344628), ('layer3.1.relu_0_output_0', 187, 0.0025350128), ('layer3.0.relu_0_output_0', 29, 0.0025902148), ('layer3.1.relu_0_output_0', 222, 0.0026126646), ('layer2.1.relu_0_output_0', 25, 0.0026373896), ('layer4.0.relu_0_output_0', 149, 0.0026412578), ('layer3.0.relu_0_output_0', 207, 0.0026680147), ('layer4.1.relu_0_output_0', 43, 0.0026766872), ('layer4.0.relu_0_output_0', 358, 0.002733374), ('layer4.1.relu_0_output_0', 33, 0.0027337142), ('layer4.0.relu_0_output_0', 207, 0.0027400868)]\n",
      "Reduce output channels for conv layer layer1.0. from 63 to 62\n",
      "Reduce bn layer layer1.0. from 63 to 62\n",
      "Reduce output channels for conv layer layer2.0. from 121 to 115\n",
      "Reduce bn layer layer2.0. from 121 to 115\n",
      "Reduce output channels for conv layer layer2.1. from 120 to 118\n",
      "Reduce bn layer layer2.1. from 120 to 118\n",
      "Reduce output channels for conv layer layer3.0. from 234 to 219\n",
      "Reduce bn layer layer3.0. from 234 to 219\n",
      "Reduce output channels for conv layer layer3.1. from 233 to 222\n",
      "Reduce bn layer layer3.1. from 233 to 222\n",
      "Reduce output channels for conv layer layer4.0. from 451 to 421\n",
      "Reduce bn layer layer4.0. from 451 to 421\n",
      "Reduce output channels for conv layer layer4.1. from 435 to 400\n",
      "Reduce bn layer layer4.1. from 435 to 400\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-205852-lnga for pruning step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-20-58-52-562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 20:58:55 Starting - Starting the training job...\n",
      "2020-05-02 20:58:57 Starting - Launching requested ML instances...\n",
      "2020-05-02 20:59:55 Starting - Preparing the instances for training............\n",
      "2020-05-02 21:01:43 Downloading - Downloading input data......\n",
      "2020-05-02 21:02:39 Training - Downloading the training image............\n",
      "2020-05-02 21:04:45 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:46,569 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:46,598 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:46,599 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:47,509 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:47,509 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:47,510 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:47,510 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpyfpua60a/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=34354677 sha256=63fbd43095e0ce95d2f83e4521fdbfaaa5a48fe795828a17b00281ac2474ddf9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g5uma2fc/wheels/54/ab/d9/af5b4dbc7d82dca7c0d2ad9ae115c55da5470b8974182ac9ff\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:04:53,375 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-20-58-52-562\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-58-52-562/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-58-52-562/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-20-58-52-562\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-58-52-562/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:04:55.697 algo-1:53 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:04:55.697 algo-1:53 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:04:55.698 algo-1:53 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:04:58.317 algo-1:53 INFO hook.py:326] Monitoring the collections: custom_collection, losses\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3599\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8831\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.3524\u001b[0m\n",
      "\u001b[34macc:0.8856\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.3523\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.3443\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.3279\u001b[0m\n",
      "\u001b[34macc:0.8955\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.3149\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.3050\u001b[0m\n",
      "\u001b[34macc:0.9005\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2968\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2896\u001b[0m\n",
      "\u001b[34macc:0.8881\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2943\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:14:25.672 algo-1:53 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:14:26,032 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 21:14:59 Uploading - Uploading generated training model\n",
      "2020-05-02 21:14:59 Completed - Training job completed\n",
      "Training seconds: 796\n",
      "Billable seconds: 796\n",
      "Training job pytorch-training-2020-05-02-20-58-52-562  finished.\n",
      "[2020-05-02 21:15:13.898 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-20-58-52-562/debug-output\n",
      "[2020-05-02 21:15:14.404 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 21:15:15.421 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer3.1.relu_0_output_0', 18, 1.5948088e-05), ('layer3.0.relu_0_output_0', 165, 1.8235058e-05), ('layer3.0.relu_0_output_0', 164, 0.00022279033), ('layer2.1.relu_0_output_0', 85, 0.0002279559), ('layer4.1.relu_0_output_0', 317, 0.00022830155), ('layer3.1.relu_0_output_0', 75, 0.0002379456), ('layer3.1.relu_0_output_0', 155, 0.00026017352), ('layer2.0.relu_0_output_0', 43, 0.00031611408), ('layer2.1.relu_0_output_0', 13, 0.0003342089), ('layer4.1.relu_0_output_0', 111, 0.00042057657), ('layer1.1.relu_0_output_0', 3, 0.0004532655), ('layer4.0.relu_0_output_0', 392, 0.00047982726), ('layer4.1.relu_0_output_0', 398, 0.00048159223), ('layer4.0.relu_0_output_0', 55, 0.0004894369), ('layer4.0.relu_0_output_0', 63, 0.00049673265), ('layer4.1.relu_0_output_0', 66, 0.00050555996), ('layer4.0.relu_0_output_0', 146, 0.0005065013), ('layer4.0.relu_0_output_0', 157, 0.0005085408), ('layer4.0.relu_0_output_0', 197, 0.00052894704), ('layer4.0.relu_0_output_0', 126, 0.0005844909), ('layer4.0.relu_0_output_0', 178, 0.00058644527), ('layer4.0.relu_0_output_0', 232, 0.0005982546), ('layer3.0.relu_0_output_0', 182, 0.0006098461), ('layer4.0.relu_0_output_0', 189, 0.0006162074), ('layer2.1.relu_0_output_0', 54, 0.0006262898), ('layer4.1.relu_0_output_0', 36, 0.0006647883), ('layer2.0.relu_0_output_0', 46, 0.0007261461), ('layer4.0.relu_0_output_0', 47, 0.0007365913), ('layer3.0.relu_0_output_0', 151, 0.00074468355), ('layer4.0.relu_0_output_0', 318, 0.0007939986), ('layer3.0.relu_0_output_0', 100, 0.0008100566), ('layer4.1.relu_0_output_0', 18, 0.000865966), ('layer4.0.relu_0_output_0', 136, 0.00088222616), ('layer4.1.relu_0_output_0', 24, 0.0010346432), ('layer2.0.relu_0_output_0', 38, 0.0010830975), ('layer4.0.relu_0_output_0', 154, 0.0011368922), ('layer4.1.relu_0_output_0', 229, 0.0011928667), ('layer4.1.relu_0_output_0', 216, 0.0012486057), ('layer4.1.relu_0_output_0', 42, 0.0012515602), ('layer3.1.relu_0_output_0', 157, 0.0013271425), ('layer3.1.relu_0_output_0', 47, 0.001352112), ('layer4.0.relu_0_output_0', 381, 0.0013778147), ('layer4.1.relu_0_output_0', 332, 0.0013816535), ('layer3.0.relu_0_output_0', 34, 0.0013875684), ('layer3.0.relu_0_output_0', 38, 0.0014201736), ('layer3.0.relu_0_output_0', 97, 0.0014871807), ('layer4.0.relu_0_output_0', 308, 0.0014913093), ('layer4.0.relu_0_output_0', 31, 0.0015024237), ('layer4.1.relu_0_output_0', 135, 0.0015331188), ('layer4.0.relu_0_output_0', 164, 0.0015536975), ('layer4.1.relu_0_output_0', 349, 0.0016391487), ('layer4.1.relu_0_output_0', 44, 0.00164143), ('layer3.1.relu_0_output_0', 89, 0.0016491495), ('layer4.0.relu_0_output_0', 77, 0.0017301098), ('layer4.1.relu_0_output_0', 54, 0.0018580965), ('layer4.1.relu_0_output_0', 376, 0.0018854621), ('layer3.1.relu_0_output_0', 37, 0.001899656), ('layer3.1.relu_0_output_0', 33, 0.0019306133), ('layer4.1.relu_0_output_0', 29, 0.0019511228), ('layer3.0.relu_0_output_0', 170, 0.0019515607), ('layer4.1.relu_0_output_0', 261, 0.0020088262), ('layer4.0.relu_0_output_0', 48, 0.0020121816), ('layer4.1.relu_0_output_0', 126, 0.002025657), ('layer4.0.relu_0_output_0', 360, 0.0020516918), ('layer4.1.relu_0_output_0', 270, 0.002127196), ('layer4.1.relu_0_output_0', 101, 0.0021884749), ('layer4.0.relu_0_output_0', 373, 0.002209584), ('layer4.1.relu_0_output_0', 311, 0.0022116343), ('layer3.0.relu_0_output_0', 204, 0.0022667197), ('layer4.0.relu_0_output_0', 22, 0.0022882686), ('layer2.0.relu_0_output_0', 21, 0.0023023977), ('layer4.1.relu_0_output_0', 194, 0.0023679263), ('layer2.0.relu_0_output_0', 105, 0.0023892177), ('layer4.0.relu_0_output_0', 128, 0.0024067538), ('layer4.1.relu_0_output_0', 221, 0.0024180105), ('layer2.1.relu_0_output_0', 4, 0.0024243456), ('layer4.1.relu_0_output_0', 39, 0.0024646933), ('layer4.0.relu_0_output_0', 377, 0.0024651475), ('layer4.0.relu_0_output_0', 266, 0.0024700111), ('layer2.1.relu_0_output_0', 103, 0.0025096934), ('layer4.0.relu_0_output_0', 236, 0.0025684063), ('layer3.1.relu_0_output_0', 164, 0.0025744154), ('layer3.1.relu_0_output_0', 38, 0.002626666), ('layer2.1.relu_0_output_0', 42, 0.002663866), ('layer4.1.relu_0_output_0', 329, 0.0027930331), ('layer4.1.relu_0_output_0', 143, 0.0028048626), ('layer4.0.relu_0_output_0', 4, 0.0028120473), ('layer4.1.relu_0_output_0', 200, 0.0028142005), ('layer2.0.relu_0_output_0', 56, 0.0029906814), ('layer4.0.relu_0_output_0', 75, 0.0029969239), ('layer3.1.relu_0_output_0', 17, 0.0030615553), ('layer4.1.relu_0_output_0', 237, 0.0030650666), ('layer3.1.relu_0_output_0', 215, 0.0031505863), ('layer4.0.relu_0_output_0', 324, 0.0031567623), ('layer3.1.relu_0_output_0', 118, 0.0031668597), ('layer4.0.relu_0_output_0', 302, 0.0031800184), ('layer3.1.relu_0_output_0', 135, 0.0031996882), ('layer4.1.relu_0_output_0', 27, 0.0032445183), ('layer4.0.relu_0_output_0', 203, 0.0033181577), ('layer2.0.relu_0_output_0', 65, 0.003390163)]\n",
      "Reduce output channels for conv layer layer1.1. from 63 to 62\n",
      "Reduce bn layer layer1.1. from 63 to 62\n",
      "Reduce output channels for conv layer layer2.0. from 115 to 108\n",
      "Reduce bn layer layer2.0. from 115 to 108\n",
      "Reduce output channels for conv layer layer2.1. from 118 to 112\n",
      "Reduce bn layer layer2.1. from 118 to 112\n",
      "Reduce output channels for conv layer layer3.0. from 219 to 209\n",
      "Reduce bn layer layer3.0. from 219 to 209\n",
      "Reduce output channels for conv layer layer3.1. from 222 to 208\n",
      "Reduce bn layer layer3.1. from 222 to 208\n",
      "Reduce output channels for conv layer layer4.0. from 421 to 389\n",
      "Reduce bn layer layer4.0. from 421 to 389\n",
      "Reduce output channels for conv layer layer4.1. from 400 to 370\n",
      "Reduce bn layer layer4.1. from 400 to 370\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-211705-hvbr for pruning step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-21-17-05-830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 21:17:08 Starting - Starting the training job...\n",
      "2020-05-02 21:17:10 Starting - Launching requested ML instances......\n",
      "2020-05-02 21:18:34 Starting - Preparing the instances for training............\n",
      "2020-05-02 21:20:25 Downloading - Downloading input data......\n",
      "2020-05-02 21:21:33 Training - Downloading the training image..............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:48,101 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:48,129 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:49,547 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:50,417 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:50,417 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:50,417 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:50,418 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpmk7lu98s/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=32037735 sha256=c6e6d217047b607ec830037c0bbd7c8fc7cb74b4f42170a17b40476ead78bb91\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-920rjav6/wheels/dd/cc/a9/00b046369e98590385d44661876a4a955634b9661db6081852\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\n",
      "2020-05-02 21:23:47 Training - Training image download completed. Training in progress.\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:23:56,306 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-21-17-05-830\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-17-05-830/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-17-05-830/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-21-17-05-830\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-17-05-830/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:23:58.371 algo-1:51 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:23:58.371 algo-1:51 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:23:58.371 algo-1:51 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:24:01.153 algo-1:51 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3248\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8905\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.3080\u001b[0m\n",
      "\u001b[34macc:0.8831\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.3139\u001b[0m\n",
      "\u001b[34macc:0.8955\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2916\u001b[0m\n",
      "\u001b[34macc:0.8955\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.3023\u001b[0m\n",
      "\u001b[34macc:0.8856\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2830\u001b[0m\n",
      "\u001b[34macc:0.9030\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2777\u001b[0m\n",
      "\u001b[34macc:0.8980\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2715\u001b[0m\n",
      "\u001b[34macc:0.8930\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2627\u001b[0m\n",
      "\u001b[34macc:0.8831\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2747\u001b[0m\n",
      "\u001b[34macc:0.9005\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:33:20.019 algo-1:51 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:33:20,452 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 21:34:00 Uploading - Uploading generated training model\n",
      "2020-05-02 21:34:00 Completed - Training job completed\n",
      "Training seconds: 815\n",
      "Billable seconds: 815\n",
      "Training job pytorch-training-2020-05-02-21-17-05-830  finished.\n",
      "[2020-05-02 21:34:28.084 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-17-05-830/debug-output\n",
      "[2020-05-02 21:34:28.597 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 21:34:29.616 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.1.relu_0_output_0', 90, 4.3235686e-05), ('layer4.0.relu_0_output_0', 268, 7.412514e-05), ('layer4.0.relu_0_output_0', 215, 0.00017433807), ('layer4.0.relu_0_output_0', 366, 0.00017959945), ('layer4.0.relu_0_output_0', 382, 0.0002470982), ('layer4.0.relu_0_output_0', 65, 0.0003582101), ('layer4.0.relu_0_output_0', 264, 0.0003596959), ('layer4.1.relu_0_output_0', 262, 0.0003706512), ('layer3.0.relu_0_output_0', 116, 0.00040559398), ('layer4.0.relu_0_output_0', 198, 0.0004254614), ('layer4.1.relu_0_output_0', 268, 0.00045917265), ('layer4.1.relu_0_output_0', 67, 0.00046657556), ('layer4.0.relu_0_output_0', 146, 0.0004914738), ('layer4.1.relu_0_output_0', 81, 0.0005006961), ('layer4.1.relu_0_output_0', 16, 0.0005454773), ('layer4.0.relu_0_output_0', 351, 0.0005666599), ('layer4.0.relu_0_output_0', 273, 0.0005672967), ('layer4.1.relu_0_output_0', 102, 0.0006233411), ('layer4.0.relu_0_output_0', 68, 0.00063787994), ('layer4.0.relu_0_output_0', 222, 0.0007500831), ('layer4.0.relu_0_output_0', 34, 0.0008036853), ('layer4.1.relu_0_output_0', 161, 0.00083030364), ('layer4.1.relu_0_output_0', 199, 0.0008314537), ('layer4.1.relu_0_output_0', 145, 0.00084632204), ('layer4.0.relu_0_output_0', 344, 0.00097097695), ('layer1.1.relu_0_output_0', 45, 0.0010168086), ('layer3.0.relu_0_output_0', 42, 0.0011327964), ('layer4.0.relu_0_output_0', 51, 0.0011668741), ('layer4.1.relu_0_output_0', 93, 0.0011799366), ('layer4.0.relu_0_output_0', 74, 0.0012104703), ('layer4.0.relu_0_output_0', 307, 0.001249091), ('layer3.1.relu_0_output_0', 90, 0.001319732), ('layer3.0.relu_0_output_0', 66, 0.001323683), ('layer4.0.relu_0_output_0', 18, 0.0013724061), ('layer3.1.relu_0_output_0', 162, 0.0014024659), ('layer4.1.relu_0_output_0', 106, 0.0014131246), ('layer4.0.relu_0_output_0', 249, 0.0014375504), ('layer4.0.relu_0_output_0', 279, 0.0014571267), ('layer3.1.relu_0_output_0', 83, 0.0015423592), ('layer4.0.relu_0_output_0', 253, 0.0015572986), ('layer4.0.relu_0_output_0', 380, 0.0015717123), ('layer4.1.relu_0_output_0', 52, 0.0016454458), ('layer4.0.relu_0_output_0', 6, 0.0016564948), ('layer4.0.relu_0_output_0', 289, 0.001662723), ('layer3.1.relu_0_output_0', 102, 0.0016810063), ('layer4.1.relu_0_output_0', 168, 0.0017361932), ('layer4.1.relu_0_output_0', 241, 0.0018454506), ('layer3.0.relu_0_output_0', 23, 0.0018732775), ('layer4.1.relu_0_output_0', 74, 0.0019240531), ('layer3.0.relu_0_output_0', 155, 0.0019757939), ('layer4.0.relu_0_output_0', 318, 0.002021791), ('layer4.1.relu_0_output_0', 80, 0.0021191768), ('layer4.0.relu_0_output_0', 63, 0.0021208462), ('layer4.1.relu_0_output_0', 367, 0.002121644), ('layer4.0.relu_0_output_0', 274, 0.002157406), ('layer4.0.relu_0_output_0', 195, 0.0021884006), ('layer4.0.relu_0_output_0', 130, 0.0022189792), ('layer4.0.relu_0_output_0', 165, 0.0022463552), ('layer4.1.relu_0_output_0', 209, 0.0022846179), ('layer2.0.relu_0_output_0', 66, 0.0023002776), ('layer2.1.relu_0_output_0', 24, 0.0023029975), ('layer4.0.relu_0_output_0', 89, 0.0023523036), ('layer3.1.relu_0_output_0', 112, 0.0024084423), ('layer4.1.relu_0_output_0', 364, 0.0024111632), ('layer4.1.relu_0_output_0', 219, 0.0024988563), ('layer4.1.relu_0_output_0', 197, 0.0025326111), ('layer4.0.relu_0_output_0', 33, 0.0026519608), ('layer3.0.relu_0_output_0', 52, 0.0027236887), ('layer4.0.relu_0_output_0', 365, 0.0027249078), ('layer4.1.relu_0_output_0', 251, 0.002797349), ('layer2.0.relu_0_output_0', 25, 0.0028521928), ('layer4.0.relu_0_output_0', 86, 0.0029034968), ('layer4.0.relu_0_output_0', 206, 0.0029298072), ('layer4.1.relu_0_output_0', 6, 0.002935778), ('layer3.0.relu_0_output_0', 114, 0.0029593513), ('layer3.1.relu_0_output_0', 48, 0.0029748657), ('layer4.0.relu_0_output_0', 247, 0.003036601), ('layer1.0.relu_0_output_0', 57, 0.0030580002), ('layer4.1.relu_0_output_0', 288, 0.0031075932), ('layer2.1.relu_0_output_0', 49, 0.003145913), ('layer4.0.relu_0_output_0', 327, 0.0031571563), ('layer4.1.relu_0_output_0', 301, 0.0032972912), ('layer4.1.relu_0_output_0', 141, 0.0033126264), ('layer2.1.relu_0_output_0', 81, 0.0033278049), ('layer4.1.relu_0_output_0', 176, 0.0033331246), ('layer4.0.relu_0_output_0', 125, 0.0033369167), ('layer4.0.relu_0_output_0', 225, 0.0034844964), ('layer3.0.relu_0_output_0', 96, 0.0034944296), ('layer4.1.relu_0_output_0', 144, 0.0035007175), ('layer4.1.relu_0_output_0', 334, 0.0035259768), ('layer4.1.relu_0_output_0', 64, 0.0035288), ('layer3.0.relu_0_output_0', 185, 0.0035427783), ('layer3.0.relu_0_output_0', 30, 0.0035890068), ('layer4.1.relu_0_output_0', 250, 0.0036008207), ('layer4.0.relu_0_output_0', 197, 0.003606756), ('layer4.1.relu_0_output_0', 244, 0.0037155915), ('layer4.0.relu_0_output_0', 358, 0.0037485296), ('layer4.0.relu_0_output_0', 169, 0.003796555), ('layer4.0.relu_0_output_0', 15, 0.0038060714), ('layer4.1.relu_0_output_0', 342, 0.00382287)]\n",
      "Reduce output channels for conv layer layer1.0. from 62 to 61\n",
      "Reduce bn layer layer1.0. from 62 to 61\n",
      "Reduce output channels for conv layer layer1.1. from 62 to 61\n",
      "Reduce bn layer layer1.1. from 62 to 61\n",
      "Reduce output channels for conv layer layer2.0. from 108 to 106\n",
      "Reduce bn layer layer2.0. from 108 to 106\n",
      "Reduce output channels for conv layer layer2.1. from 112 to 109\n",
      "Reduce bn layer layer2.1. from 112 to 109\n",
      "Reduce output channels for conv layer layer3.0. from 209 to 199\n",
      "Reduce bn layer layer3.0. from 209 to 199\n",
      "Reduce output channels for conv layer layer3.1. from 208 to 202\n",
      "Reduce bn layer layer3.1. from 208 to 202\n",
      "Reduce output channels for conv layer layer4.0. from 389 to 346\n",
      "Reduce bn layer layer4.0. from 389 to 346\n",
      "Reduce output channels for conv layer layer4.1. from 370 to 336\n",
      "Reduce bn layer layer4.1. from 370 to 336\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-213620-dzty for pruning step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-21-36-21-118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 21:36:23 Starting - Starting the training job...\n",
      "2020-05-02 21:36:25 Starting - Launching requested ML instances......\n",
      "2020-05-02 21:37:48 Starting - Preparing the instances for training.........\n",
      "2020-05-02 21:39:16 Downloading - Downloading input data......\n",
      "2020-05-02 21:40:22 Training - Downloading the training image...............\n",
      "2020-05-02 21:42:38 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:39,840 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:39,870 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:42,899 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:43,711 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:43,711 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:43,712 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:43,712 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpbro5o3oj/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=29491300 sha256=aab2c4e40af158a74849bab04fdcf9b017ec224a7226e1cf47825cc333ef0e3a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-izl4sut1/wheels/04/c7/5e/f6d03d2354edf8c18b5e71939822d963f69b5247fff8336d31\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:42:49,666 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-21-36-21-118\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-36-21-118/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-36-21-118/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-21-36-21-118\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-36-21-118/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:42:51.728 algo-1:51 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:42:51.729 algo-1:51 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:42:51.729 algo-1:51 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:42:54.617 algo-1:51 INFO hook.py:326] Monitoring the collections: custom_collection, losses\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.2996\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8905\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.3041\u001b[0m\n",
      "\u001b[34macc:0.9055\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.2952\u001b[0m\n",
      "\u001b[34macc:0.8930\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2825\u001b[0m\n",
      "\u001b[34macc:0.8930\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2649\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2620\u001b[0m\n",
      "\u001b[34macc:0.9030\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2641\u001b[0m\n",
      "\u001b[34macc:0.9080\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2577\u001b[0m\n",
      "\u001b[34macc:0.8955\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2496\u001b[0m\n",
      "\u001b[34macc:0.8930\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2562\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34m[2020-05-02 21:52:19.897 algo-1:51 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 21:52:20,336 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 21:52:52 Uploading - Uploading generated training model\n",
      "2020-05-02 21:52:52 Completed - Training job completed\n",
      "Training seconds: 816\n",
      "Billable seconds: 816\n",
      "Training job pytorch-training-2020-05-02-21-36-21-118  finished.\n",
      "[2020-05-02 21:53:12.793 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-36-21-118/debug-output\n",
      "[2020-05-02 21:53:13.255 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 21:53:14.274 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.0.relu_0_output_0', 262, 4.691492e-05), ('layer4.0.relu_0_output_0', 43, 7.823068e-05), ('layer4.0.relu_0_output_0', 335, 9.877621e-05), ('layer3.1.relu_0_output_0', 95, 0.00010318969), ('layer3.0.relu_0_output_0', 79, 0.00013018609), ('layer3.0.relu_0_output_0', 159, 0.00017589796), ('layer4.0.relu_0_output_0', 44, 0.0003031346), ('layer4.0.relu_0_output_0', 206, 0.00031429314), ('layer1.1.relu_0_output_0', 36, 0.00034259516), ('layer3.1.relu_0_output_0', 17, 0.00050305424), ('layer1.0.relu_0_output_0', 9, 0.00057613547), ('layer4.1.relu_0_output_0', 59, 0.0005888801), ('layer4.0.relu_0_output_0', 320, 0.000703239), ('layer4.0.relu_0_output_0', 126, 0.0007881401), ('layer4.1.relu_0_output_0', 203, 0.00085273705), ('layer4.1.relu_0_output_0', 156, 0.00092286494), ('layer3.1.relu_0_output_0', 63, 0.0009478897), ('layer4.1.relu_0_output_0', 15, 0.0009567963), ('layer2.1.relu_0_output_0', 66, 0.0009823861), ('layer3.0.relu_0_output_0', 103, 0.0010151285), ('layer3.1.relu_0_output_0', 70, 0.0010180568), ('layer4.1.relu_0_output_0', 102, 0.0010831357), ('layer4.1.relu_0_output_0', 170, 0.0011017782), ('layer4.0.relu_0_output_0', 106, 0.0011039191), ('layer4.0.relu_0_output_0', 218, 0.0011101098), ('layer4.0.relu_0_output_0', 326, 0.0011110847), ('layer4.1.relu_0_output_0', 87, 0.0011465987), ('layer3.0.relu_0_output_0', 86, 0.0012283294), ('layer3.0.relu_0_output_0', 83, 0.0012430204), ('layer4.1.relu_0_output_0', 134, 0.0012476958), ('layer3.1.relu_0_output_0', 123, 0.0012495405), ('layer4.1.relu_0_output_0', 273, 0.0012658817), ('layer2.0.relu_0_output_0', 48, 0.0013961401), ('layer3.0.relu_0_output_0', 151, 0.001414859), ('layer4.1.relu_0_output_0', 89, 0.001495606), ('layer4.0.relu_0_output_0', 65, 0.0014956614), ('layer4.1.relu_0_output_0', 249, 0.0015148877), ('layer2.0.relu_0_output_0', 44, 0.0015353287), ('layer3.0.relu_0_output_0', 33, 0.0015714347), ('layer4.0.relu_0_output_0', 226, 0.0015831598), ('layer4.1.relu_0_output_0', 206, 0.001666184), ('layer4.0.relu_0_output_0', 248, 0.0016801899), ('layer3.0.relu_0_output_0', 174, 0.0017289388), ('layer4.1.relu_0_output_0', 120, 0.0017865312), ('layer3.0.relu_0_output_0', 146, 0.0018080274), ('layer4.1.relu_0_output_0', 228, 0.0019045108), ('layer4.1.relu_0_output_0', 113, 0.0019148099), ('layer4.1.relu_0_output_0', 246, 0.0019227667), ('layer4.1.relu_0_output_0', 150, 0.0019488935), ('layer4.1.relu_0_output_0', 173, 0.0019726467), ('layer3.0.relu_0_output_0', 127, 0.0020015726), ('layer4.1.relu_0_output_0', 289, 0.0020182617), ('layer4.0.relu_0_output_0', 229, 0.0020198927), ('layer4.1.relu_0_output_0', 224, 0.002066305), ('layer1.0.relu_0_output_0', 4, 0.002086712), ('layer4.0.relu_0_output_0', 192, 0.0022360396), ('layer4.1.relu_0_output_0', 135, 0.0022542304), ('layer4.0.relu_0_output_0', 138, 0.0022929993), ('layer4.1.relu_0_output_0', 193, 0.002455873), ('layer4.1.relu_0_output_0', 136, 0.002482855), ('layer3.0.relu_0_output_0', 39, 0.0024834874), ('layer4.1.relu_0_output_0', 4, 0.002536161), ('layer4.1.relu_0_output_0', 118, 0.0026030955), ('layer3.1.relu_0_output_0', 146, 0.0026104178), ('layer4.0.relu_0_output_0', 304, 0.0027543562), ('layer4.1.relu_0_output_0', 167, 0.0027615249), ('layer4.0.relu_0_output_0', 149, 0.002763603), ('layer4.0.relu_0_output_0', 188, 0.0027927458), ('layer3.0.relu_0_output_0', 124, 0.0028814944), ('layer4.1.relu_0_output_0', 281, 0.0029382503), ('layer3.0.relu_0_output_0', 95, 0.003075421), ('layer4.0.relu_0_output_0', 26, 0.003183245), ('layer3.1.relu_0_output_0', 182, 0.0031833772), ('layer4.0.relu_0_output_0', 163, 0.0032792757), ('layer1.0.relu_0_output_0', 11, 0.0033188432), ('layer3.0.relu_0_output_0', 15, 0.0033446641), ('layer4.1.relu_0_output_0', 168, 0.0033687914), ('layer4.1.relu_0_output_0', 20, 0.0033796567), ('layer4.0.relu_0_output_0', 83, 0.0033999558), ('layer4.1.relu_0_output_0', 96, 0.0034183017), ('layer4.0.relu_0_output_0', 329, 0.0034247749), ('layer3.1.relu_0_output_0', 137, 0.0034584333), ('layer2.0.relu_0_output_0', 59, 0.0034618957), ('layer4.1.relu_0_output_0', 17, 0.0034680557), ('layer2.0.relu_0_output_0', 58, 0.003589779), ('layer4.1.relu_0_output_0', 137, 0.0035921542), ('layer3.0.relu_0_output_0', 122, 0.0036280584), ('layer3.0.relu_0_output_0', 125, 0.0036589473), ('layer4.1.relu_0_output_0', 316, 0.0037630757), ('layer4.0.relu_0_output_0', 113, 0.0038232727), ('layer4.0.relu_0_output_0', 288, 0.0038314841), ('layer4.0.relu_0_output_0', 104, 0.003871718), ('layer4.1.relu_0_output_0', 98, 0.0038729052), ('layer2.1.relu_0_output_0', 19, 0.0039217165), ('layer4.0.relu_0_output_0', 64, 0.0039434647), ('layer4.0.relu_0_output_0', 244, 0.0041116495), ('layer4.1.relu_0_output_0', 12, 0.004193658), ('layer3.1.relu_0_output_0', 31, 0.0042151553), ('layer4.0.relu_0_output_0', 191, 0.0042355615), ('layer4.0.relu_0_output_0', 270, 0.004282074)]\n",
      "Reduce output channels for conv layer layer1.0. from 61 to 58\n",
      "Reduce bn layer layer1.0. from 61 to 58\n",
      "Reduce output channels for conv layer layer1.1. from 61 to 60\n",
      "Reduce bn layer layer1.1. from 61 to 60\n",
      "Reduce output channels for conv layer layer2.0. from 106 to 102\n",
      "Reduce bn layer layer2.0. from 106 to 102\n",
      "Reduce output channels for conv layer layer2.1. from 109 to 107\n",
      "Reduce bn layer layer2.1. from 109 to 107\n",
      "Reduce output channels for conv layer layer3.0. from 199 to 183\n",
      "Reduce bn layer layer3.0. from 199 to 183\n",
      "Reduce output channels for conv layer layer3.1. from 202 to 193\n",
      "Reduce bn layer layer3.1. from 202 to 193\n",
      "Reduce output channels for conv layer layer4.0. from 346 to 316\n",
      "Reduce bn layer layer4.0. from 346 to 316\n",
      "Reduce output channels for conv layer layer4.1. from 336 to 301\n",
      "Reduce bn layer layer4.1. from 336 to 301\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-215457-lunq for pruning step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-21-54-57-619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 21:55:00 Starting - Starting the training job...\n",
      "2020-05-02 21:55:01 Starting - Launching requested ML instances...\n",
      "2020-05-02 21:55:59 Starting - Preparing the instances for training............\n",
      "2020-05-02 21:57:35 Downloading - Downloading input data......\n",
      "2020-05-02 21:58:52 Training - Downloading the training image...........\n",
      "2020-05-02 22:00:39 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:40,122 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:40,150 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:46,365 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:47,168 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:47,168 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:47,169 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:47,169 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpsopimvsm/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=27102897 sha256=3b2de667641a1cfe0b70366af2d51118ec32efa0040964d0c3e5e58061d2fb46\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-errq95ej/wheels/7d/4c/fe/112a61934e76b762f6bb4741187d7efee4d814e1903f44f42b\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:00:52,193 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-21-54-57-619\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-54-57-619/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-54-57-619/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-21-54-57-619\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-54-57-619/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:00:54.120 algo-1:52 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:00:54.121 algo-1:52 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:00:54.121 algo-1:52 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:00:56.899 algo-1:52 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3045\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8731\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.2926\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.2770\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2789\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2671\u001b[0m\n",
      "\u001b[34macc:0.8756\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2647\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2550\u001b[0m\n",
      "\u001b[34macc:0.8756\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2450\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2464\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2621\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:10:12.798 algo-1:52 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:10:13,209 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 22:11:07 Uploading - Uploading generated training model\n",
      "2020-05-02 22:11:07 Completed - Training job completed\n",
      "Training seconds: 812\n",
      "Billable seconds: 812\n",
      "Training job pytorch-training-2020-05-02-21-54-57-619  finished.\n",
      "[2020-05-02 22:11:19.356 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-21-54-57-619/debug-output\n",
      "[2020-05-02 22:11:19.760 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 22:11:20.775 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.0.relu_0_output_0', 203, 1.1607724e-05), ('layer3.0.relu_0_output_0', 18, 2.2441547e-05), ('layer4.0.relu_0_output_0', 221, 3.3461e-05), ('layer4.0.relu_0_output_0', 142, 3.8347524e-05), ('layer4.1.relu_0_output_0', 171, 4.9411068e-05), ('layer1.0.relu_0_output_0', 19, 8.46965e-05), ('layer3.1.relu_0_output_0', 149, 0.00011795261), ('layer2.1.relu_0_output_0', 58, 0.00017749728), ('layer3.1.relu_0_output_0', 59, 0.00020554596), ('layer3.1.relu_0_output_0', 78, 0.00026678483), ('layer3.1.relu_0_output_0', 0, 0.00029790073), ('layer4.0.relu_0_output_0', 133, 0.00042243535), ('layer4.1.relu_0_output_0', 17, 0.00043496155), ('layer4.0.relu_0_output_0', 1, 0.00044609013), ('layer2.1.relu_0_output_0', 75, 0.00047050402), ('layer4.0.relu_0_output_0', 186, 0.00049422134), ('layer4.0.relu_0_output_0', 9, 0.0005117876), ('layer4.0.relu_0_output_0', 94, 0.0005366016), ('layer3.1.relu_0_output_0', 119, 0.0005800222), ('layer4.1.relu_0_output_0', 142, 0.00064550026), ('layer4.1.relu_0_output_0', 111, 0.00067411474), ('layer4.0.relu_0_output_0', 265, 0.0007723891), ('layer4.0.relu_0_output_0', 102, 0.00089339603), ('layer4.0.relu_0_output_0', 188, 0.00095470663), ('layer4.0.relu_0_output_0', 250, 0.0009777192), ('layer3.1.relu_0_output_0', 126, 0.0010897608), ('layer3.1.relu_0_output_0', 120, 0.001112107), ('layer4.0.relu_0_output_0', 20, 0.0013119021), ('layer4.1.relu_0_output_0', 280, 0.0014922108), ('layer4.1.relu_0_output_0', 49, 0.0015296168), ('layer4.1.relu_0_output_0', 31, 0.0015337551), ('layer4.0.relu_0_output_0', 215, 0.0015338573), ('layer3.1.relu_0_output_0', 146, 0.0015968079), ('layer4.1.relu_0_output_0', 119, 0.001696442), ('layer4.1.relu_0_output_0', 264, 0.0017335166), ('layer4.0.relu_0_output_0', 111, 0.001828705), ('layer4.1.relu_0_output_0', 121, 0.0018958478), ('layer2.1.relu_0_output_0', 16, 0.0019048739), ('layer4.0.relu_0_output_0', 149, 0.0019459362), ('layer4.1.relu_0_output_0', 105, 0.001954213), ('layer3.0.relu_0_output_0', 164, 0.0020242524), ('layer4.0.relu_0_output_0', 114, 0.0021526176), ('layer4.1.relu_0_output_0', 256, 0.002160672), ('layer4.0.relu_0_output_0', 205, 0.0022153347), ('layer4.0.relu_0_output_0', 74, 0.0022226826), ('layer3.1.relu_0_output_0', 13, 0.0023262154), ('layer3.0.relu_0_output_0', 37, 0.0023522603), ('layer2.1.relu_0_output_0', 28, 0.0023554217), ('layer3.0.relu_0_output_0', 62, 0.0024314958), ('layer4.0.relu_0_output_0', 301, 0.002510858), ('layer2.0.relu_0_output_0', 88, 0.0025915639), ('layer3.1.relu_0_output_0', 123, 0.0025986957), ('layer4.0.relu_0_output_0', 39, 0.002618563), ('layer3.0.relu_0_output_0', 24, 0.0026225056), ('layer4.1.relu_0_output_0', 228, 0.0026399868), ('layer2.0.relu_0_output_0', 8, 0.0026511813), ('layer3.1.relu_0_output_0', 86, 0.0026591865), ('layer4.1.relu_0_output_0', 117, 0.0029051574), ('layer3.0.relu_0_output_0', 91, 0.0029729188), ('layer4.1.relu_0_output_0', 98, 0.003095478), ('layer4.0.relu_0_output_0', 97, 0.003105307), ('layer4.1.relu_0_output_0', 181, 0.0031931829), ('layer4.1.relu_0_output_0', 46, 0.0032654987), ('layer3.0.relu_0_output_0', 60, 0.0033240495), ('layer1.0.relu_0_output_0', 50, 0.0033460623), ('layer2.1.relu_0_output_0', 106, 0.0034326261), ('layer3.0.relu_0_output_0', 179, 0.0034877595), ('layer3.0.relu_0_output_0', 170, 0.0035359606), ('layer3.0.relu_0_output_0', 96, 0.0036467835), ('layer4.0.relu_0_output_0', 310, 0.003649191), ('layer4.1.relu_0_output_0', 224, 0.0037030159), ('layer4.0.relu_0_output_0', 104, 0.0037077398), ('layer4.0.relu_0_output_0', 234, 0.0037854845), ('layer4.1.relu_0_output_0', 299, 0.0038228708), ('layer4.0.relu_0_output_0', 147, 0.0038520074), ('layer4.0.relu_0_output_0', 314, 0.003863951), ('layer3.0.relu_0_output_0', 57, 0.0038766835), ('layer3.0.relu_0_output_0', 22, 0.0039011433), ('layer2.0.relu_0_output_0', 68, 0.003958004), ('layer4.0.relu_0_output_0', 302, 0.0039663133), ('layer4.0.relu_0_output_0', 222, 0.0039890176), ('layer3.1.relu_0_output_0', 113, 0.0039978656), ('layer4.0.relu_0_output_0', 242, 0.0040340596), ('layer4.1.relu_0_output_0', 16, 0.0040733926), ('layer4.1.relu_0_output_0', 284, 0.0040905424), ('layer4.0.relu_0_output_0', 70, 0.004116398), ('layer4.1.relu_0_output_0', 208, 0.0043129674), ('layer3.0.relu_0_output_0', 120, 0.0043248693), ('layer4.1.relu_0_output_0', 38, 0.004354597), ('layer3.1.relu_0_output_0', 175, 0.0043625836), ('layer4.1.relu_0_output_0', 91, 0.0044712136), ('layer3.0.relu_0_output_0', 87, 0.0045615775), ('layer3.1.relu_0_output_0', 71, 0.0045744134), ('layer3.0.relu_0_output_0', 94, 0.0045900885), ('layer3.1.relu_0_output_0', 9, 0.0046939277), ('layer3.1.relu_0_output_0', 187, 0.0048422944), ('layer4.1.relu_0_output_0', 78, 0.004875022), ('layer4.0.relu_0_output_0', 92, 0.004881406), ('layer4.0.relu_0_output_0', 232, 0.0049245846), ('layer2.0.relu_0_output_0', 49, 0.0049246135)]\n",
      "Reduce output channels for conv layer layer1.0. from 58 to 56\n",
      "Reduce bn layer layer1.0. from 58 to 56\n",
      "Reduce output channels for conv layer layer2.0. from 102 to 98\n",
      "Reduce bn layer layer2.0. from 102 to 98\n",
      "Reduce output channels for conv layer layer2.1. from 107 to 102\n",
      "Reduce bn layer layer2.1. from 107 to 102\n",
      "Reduce output channels for conv layer layer3.0. from 183 to 168\n",
      "Reduce bn layer layer3.0. from 183 to 168\n",
      "Reduce output channels for conv layer layer3.1. from 193 to 177\n",
      "Reduce bn layer layer3.1. from 193 to 177\n",
      "Reduce output channels for conv layer layer4.0. from 316 to 283\n",
      "Reduce bn layer layer4.0. from 316 to 283\n",
      "Reduce output channels for conv layer layer4.1. from 301 to 276\n",
      "Reduce bn layer layer4.1. from 301 to 276\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-221310-iwfl for pruning step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-22-13-11-011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 22:13:13 Starting - Starting the training job...\n",
      "2020-05-02 22:13:14 Starting - Launching requested ML instances...\n",
      "2020-05-02 22:14:12 Starting - Preparing the instances for training............\n",
      "2020-05-02 22:16:03 Downloading - Downloading input data.........\n",
      "2020-05-02 22:17:34 Training - Downloading the training image............\n",
      "2020-05-02 22:19:26 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,207 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,237 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,239 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,988 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,988 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,988 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:28,989 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpqnooo7a0/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=24856318 sha256=c6cac0dbfb03ac9d9bbb82bc1b5ffd4aee64a6a942f4ebd355e20fb45a39e402\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b4u6q7v0/wheels/34/28/bb/4f727223279312bb7f1d89512cd5a53053e2c13976e762ab1e\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:19:34,173 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-22-13-11-011\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-13-11-011/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-13-11-011/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-22-13-11-011\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-13-11-011/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:19:36.461 algo-1:48 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:19:36.462 algo-1:48 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:19:36.462 algo-1:48 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:19:39.488 algo-1:48 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3118\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8831\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.2817\u001b[0m\n",
      "\u001b[34macc:0.8682\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.2701\u001b[0m\n",
      "\u001b[34macc:0.8881\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2774\u001b[0m\n",
      "\u001b[34macc:0.8905\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2639\u001b[0m\n",
      "\u001b[34macc:0.8881\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2439\u001b[0m\n",
      "\u001b[34macc:0.8881\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2588\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2362\u001b[0m\n",
      "\u001b[34macc:0.8781\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2293\u001b[0m\n",
      "\u001b[34macc:0.8930\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2331\u001b[0m\n",
      "\u001b[34macc:0.8831\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:28:53.828 algo-1:48 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:28:54,224 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 22:29:40 Uploading - Uploading generated training model\n",
      "2020-05-02 22:29:40 Completed - Training job completed\n",
      "Training seconds: 817\n",
      "Billable seconds: 817\n",
      "Training job pytorch-training-2020-05-02-22-13-11-011  finished.\n",
      "[2020-05-02 22:30:01.960 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-13-11-011/debug-output\n",
      "[2020-05-02 22:30:02.576 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 22:30:03.594 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.1.relu_0_output_0', 189, 3.7473896e-05), ('layer4.0.relu_0_output_0', 24, 0.00010314901), ('layer4.1.relu_0_output_0', 230, 0.00011212812), ('layer4.0.relu_0_output_0', 16, 0.00012263216), ('layer3.0.relu_0_output_0', 61, 0.0002342703), ('layer4.1.relu_0_output_0', 42, 0.00023603429), ('layer4.1.relu_0_output_0', 204, 0.00025462836), ('layer4.1.relu_0_output_0', 44, 0.00025482685), ('layer4.0.relu_0_output_0', 225, 0.00037709906), ('layer4.0.relu_0_output_0', 229, 0.00040192195), ('layer4.1.relu_0_output_0', 255, 0.00042179963), ('layer3.1.relu_0_output_0', 112, 0.00048315164), ('layer4.1.relu_0_output_0', 111, 0.00048967835), ('layer3.1.relu_0_output_0', 42, 0.0005862243), ('layer3.0.relu_0_output_0', 138, 0.00063839), ('layer4.1.relu_0_output_0', 140, 0.0006884894), ('layer2.1.relu_0_output_0', 16, 0.0007204679), ('layer4.1.relu_0_output_0', 105, 0.00079039444), ('layer1.1.relu_0_output_0', 20, 0.00087602215), ('layer4.0.relu_0_output_0', 4, 0.0008896345), ('layer4.0.relu_0_output_0', 50, 0.0008965614), ('layer4.0.relu_0_output_0', 88, 0.00092222256), ('layer4.0.relu_0_output_0', 209, 0.0009323639), ('layer4.0.relu_0_output_0', 154, 0.0009375194), ('layer3.0.relu_0_output_0', 140, 0.00096687634), ('layer4.1.relu_0_output_0', 179, 0.000985427), ('layer4.1.relu_0_output_0', 52, 0.0010381532), ('layer2.1.relu_0_output_0', 29, 0.0010519272), ('layer4.1.relu_0_output_0', 171, 0.0011737788), ('layer4.0.relu_0_output_0', 100, 0.0012570709), ('layer1.0.relu_0_output_0', 4, 0.0013197208), ('layer4.0.relu_0_output_0', 85, 0.0013458153), ('layer4.0.relu_0_output_0', 118, 0.0014469173), ('layer2.1.relu_0_output_0', 84, 0.00155492), ('layer4.1.relu_0_output_0', 10, 0.0016500477), ('layer4.0.relu_0_output_0', 282, 0.001803621), ('layer4.0.relu_0_output_0', 257, 0.0019837741), ('layer4.1.relu_0_output_0', 50, 0.001986938), ('layer4.1.relu_0_output_0', 18, 0.0021786678), ('layer4.0.relu_0_output_0', 8, 0.00235669), ('layer4.0.relu_0_output_0', 146, 0.0024311852), ('layer2.0.relu_0_output_0', 17, 0.0025233035), ('layer3.1.relu_0_output_0', 108, 0.0026383519), ('layer3.0.relu_0_output_0', 8, 0.0026459536), ('layer4.1.relu_0_output_0', 253, 0.0027444933), ('layer4.1.relu_0_output_0', 160, 0.002785207), ('layer3.1.relu_0_output_0', 104, 0.0027918506), ('layer3.1.relu_0_output_0', 138, 0.0028063955), ('layer4.1.relu_0_output_0', 144, 0.002965599), ('layer3.1.relu_0_output_0', 167, 0.0029863366), ('layer4.1.relu_0_output_0', 246, 0.0030828835), ('layer4.1.relu_0_output_0', 155, 0.0031068013), ('layer4.1.relu_0_output_0', 6, 0.0031409), ('layer2.0.relu_0_output_0', 50, 0.0031660341), ('layer3.0.relu_0_output_0', 32, 0.0032296372), ('layer3.0.relu_0_output_0', 38, 0.003231554), ('layer2.1.relu_0_output_0', 1, 0.0032651648), ('layer4.0.relu_0_output_0', 255, 0.0033885501), ('layer4.0.relu_0_output_0', 78, 0.0033944712), ('layer2.1.relu_0_output_0', 60, 0.0035403504), ('layer4.0.relu_0_output_0', 132, 0.0035986016), ('layer2.0.relu_0_output_0', 30, 0.0036570944), ('layer4.0.relu_0_output_0', 211, 0.003756913), ('layer2.0.relu_0_output_0', 48, 0.003820946), ('layer2.1.relu_0_output_0', 90, 0.003839576), ('layer4.1.relu_0_output_0', 147, 0.003876817), ('layer3.1.relu_0_output_0', 8, 0.00388535), ('layer3.0.relu_0_output_0', 88, 0.0040640673), ('layer4.1.relu_0_output_0', 102, 0.004125195), ('layer1.1.relu_0_output_0', 2, 0.004142552), ('layer3.0.relu_0_output_0', 83, 0.0041988855), ('layer3.0.relu_0_output_0', 15, 0.004224857), ('layer4.0.relu_0_output_0', 172, 0.004332568), ('layer4.0.relu_0_output_0', 62, 0.0043842196), ('layer3.0.relu_0_output_0', 45, 0.004417783), ('layer4.0.relu_0_output_0', 197, 0.004447966), ('layer4.0.relu_0_output_0', 187, 0.0044538076), ('layer2.1.relu_0_output_0', 80, 0.0044684443), ('layer4.1.relu_0_output_0', 251, 0.004503967), ('layer4.1.relu_0_output_0', 86, 0.004521554), ('layer3.1.relu_0_output_0', 47, 0.00460892), ('layer3.1.relu_0_output_0', 54, 0.0046300734), ('layer4.0.relu_0_output_0', 245, 0.004657414), ('layer2.0.relu_0_output_0', 96, 0.0046771173), ('layer2.0.relu_0_output_0', 46, 0.0047784657), ('layer2.0.relu_0_output_0', 61, 0.004802598), ('layer1.0.relu_0_output_0', 12, 0.0049518542), ('layer4.0.relu_0_output_0', 130, 0.004963688), ('layer3.0.relu_0_output_0', 62, 0.0050169434), ('layer1.1.relu_0_output_0', 39, 0.0050502527), ('layer4.1.relu_0_output_0', 224, 0.005084907), ('layer2.1.relu_0_output_0', 69, 0.00516521), ('layer4.1.relu_0_output_0', 27, 0.005198315), ('layer4.0.relu_0_output_0', 83, 0.0053421617), ('layer4.0.relu_0_output_0', 18, 0.0053814864), ('layer4.1.relu_0_output_0', 43, 0.0054647005), ('layer4.0.relu_0_output_0', 239, 0.005554059), ('layer4.1.relu_0_output_0', 143, 0.0057866336), ('layer3.1.relu_0_output_0', 67, 0.0058008167), ('layer4.0.relu_0_output_0', 202, 0.005803639)]\n",
      "Reduce output channels for conv layer layer1.0. from 56 to 54\n",
      "Reduce bn layer layer1.0. from 56 to 54\n",
      "Reduce output channels for conv layer layer1.1. from 60 to 57\n",
      "Reduce bn layer layer1.1. from 60 to 57\n",
      "Reduce output channels for conv layer layer2.0. from 98 to 91\n",
      "Reduce bn layer layer2.0. from 98 to 91\n",
      "Reduce output channels for conv layer layer2.1. from 102 to 94\n",
      "Reduce bn layer layer2.1. from 102 to 94\n",
      "Reduce output channels for conv layer layer3.0. from 168 to 157\n",
      "Reduce bn layer layer3.0. from 168 to 157\n",
      "Reduce output channels for conv layer layer3.1. from 177 to 167\n",
      "Reduce bn layer layer3.1. from 177 to 167\n",
      "Reduce output channels for conv layer layer4.0. from 283 to 253\n",
      "Reduce bn layer layer4.0. from 283 to 253\n",
      "Reduce output channels for conv layer layer4.1. from 276 to 247\n",
      "Reduce bn layer layer4.1. from 276 to 247\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-223145-noia for pruning step 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-22-31-45-762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 22:31:47 Starting - Starting the training job...\n",
      "2020-05-02 22:31:50 Starting - Launching requested ML instances......\n",
      "2020-05-02 22:33:14 Starting - Preparing the instances for training.........\n",
      "2020-05-02 22:34:38 Downloading - Downloading input data......\n",
      "2020-05-02 22:35:42 Training - Downloading the training image..............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:55,290 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:55,315 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:58,326 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:59,024 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:59,024 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:59,024 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 22:37:59,025 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp0f6kare5/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=22646508 sha256=5df30a1f4ebfa06775878141c40614d5f8b569888edef7aedb877810109cceff\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ehuogy5q/wheels/72/b1/db/3cacc693394c698530cce8bf3df04274e32732d492826bc9db\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:38:03,388 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-22-31-45-762\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-31-45-762/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-31-45-762/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-22-31-45-762\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-31-45-762/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-02 22:37:54 Training - Training image download completed. Training in progress.\u001b[34m[2020-05-02 22:38:05.236 algo-1:48 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:38:05.236 algo-1:48 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:38:05.236 algo-1:48 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:38:07.604 algo-1:48 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3058\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8632\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.2927\u001b[0m\n",
      "\u001b[34macc:0.8607\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.2709\u001b[0m\n",
      "\u001b[34macc:0.8806\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2721\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2569\u001b[0m\n",
      "\u001b[34macc:0.8582\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2657\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2465\u001b[0m\n",
      "\u001b[34macc:0.8706\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2446\u001b[0m\n",
      "\u001b[34macc:0.8731\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2494\u001b[0m\n",
      "\u001b[34macc:0.8706\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2570\u001b[0m\n",
      "\u001b[34macc:0.8756\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:46:57.369 algo-1:48 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:46:57,665 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 22:48:06 Uploading - Uploading generated training model\n",
      "2020-05-02 22:48:06 Completed - Training job completed\n",
      "Training seconds: 808\n",
      "Billable seconds: 808\n",
      "Training job pytorch-training-2020-05-02-22-31-45-762  finished.\n",
      "[2020-05-02 22:48:36.600 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-31-45-762/debug-output\n",
      "[2020-05-02 22:48:37.188 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 22:48:38.203 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.0.relu_0_output_0', 189, 9.994084e-06), ('layer4.1.relu_0_output_0', 178, 1.7967239e-05), ('layer4.0.relu_0_output_0', 52, 0.00012617483), ('layer4.0.relu_0_output_0', 169, 0.00012801285), ('layer4.0.relu_0_output_0', 175, 0.00018179163), ('layer4.0.relu_0_output_0', 7, 0.00020700843), ('layer2.0.relu_0_output_0', 27, 0.00029620295), ('layer4.0.relu_0_output_0', 60, 0.0004216295), ('layer4.1.relu_0_output_0', 85, 0.00046954755), ('layer3.1.relu_0_output_0', 42, 0.00060520886), ('layer3.0.relu_0_output_0', 148, 0.00094334024), ('layer4.0.relu_0_output_0', 105, 0.0012725155), ('layer4.1.relu_0_output_0', 57, 0.0013010914), ('layer2.1.relu_0_output_0', 21, 0.0013392424), ('layer1.1.relu_0_output_0', 40, 0.0013464844), ('layer2.1.relu_0_output_0', 86, 0.0013564444), ('layer2.0.relu_0_output_0', 33, 0.0014362123), ('layer4.1.relu_0_output_0', 121, 0.0014464698), ('layer4.1.relu_0_output_0', 169, 0.0015235009), ('layer4.1.relu_0_output_0', 234, 0.0015616134), ('layer4.1.relu_0_output_0', 210, 0.0016143334), ('layer4.0.relu_0_output_0', 187, 0.0017968811), ('layer4.1.relu_0_output_0', 0, 0.001800413), ('layer4.0.relu_0_output_0', 151, 0.0020828815), ('layer2.0.relu_0_output_0', 51, 0.0021209707), ('layer3.1.relu_0_output_0', 123, 0.002297558), ('layer1.1.relu_0_output_0', 34, 0.0024365159), ('layer4.0.relu_0_output_0', 69, 0.0026445624), ('layer3.1.relu_0_output_0', 124, 0.002653578), ('layer3.1.relu_0_output_0', 135, 0.002658972), ('layer1.1.relu_0_output_0', 20, 0.0027562655), ('layer4.1.relu_0_output_0', 244, 0.0028014374), ('layer4.1.relu_0_output_0', 185, 0.0028038116), ('layer3.1.relu_0_output_0', 109, 0.0031247898), ('layer4.1.relu_0_output_0', 37, 0.0031324709), ('layer4.0.relu_0_output_0', 82, 0.0031830592), ('layer4.1.relu_0_output_0', 240, 0.0032989283), ('layer3.1.relu_0_output_0', 20, 0.0033124515), ('layer4.0.relu_0_output_0', 149, 0.0033496663), ('layer4.0.relu_0_output_0', 45, 0.00348406), ('layer4.1.relu_0_output_0', 103, 0.0037667588), ('layer4.1.relu_0_output_0', 188, 0.003821495), ('layer3.0.relu_0_output_0', 73, 0.0038316813), ('layer4.1.relu_0_output_0', 130, 0.0040653544), ('layer4.0.relu_0_output_0', 95, 0.004138465), ('layer4.1.relu_0_output_0', 93, 0.004161265), ('layer4.0.relu_0_output_0', 183, 0.0041942485), ('layer3.0.relu_0_output_0', 54, 0.004260778), ('layer3.0.relu_0_output_0', 50, 0.004345568), ('layer3.1.relu_0_output_0', 102, 0.0044418224), ('layer4.1.relu_0_output_0', 23, 0.0045113037), ('layer4.0.relu_0_output_0', 97, 0.0046302164), ('layer3.0.relu_0_output_0', 64, 0.0047330866), ('layer4.1.relu_0_output_0', 90, 0.0047362633), ('layer4.0.relu_0_output_0', 14, 0.004758926), ('layer2.0.relu_0_output_0', 12, 0.004928483), ('layer4.1.relu_0_output_0', 143, 0.0049450523), ('layer2.1.relu_0_output_0', 88, 0.0049819746), ('layer4.1.relu_0_output_0', 208, 0.005125289), ('layer4.0.relu_0_output_0', 66, 0.00531845), ('layer3.0.relu_0_output_0', 133, 0.0053427727), ('layer4.1.relu_0_output_0', 99, 0.0054696854), ('layer1.0.relu_0_output_0', 39, 0.0054739467), ('layer3.0.relu_0_output_0', 20, 0.0054812636), ('layer3.1.relu_0_output_0', 17, 0.005485506), ('layer2.0.relu_0_output_0', 16, 0.0055193747), ('layer4.1.relu_0_output_0', 100, 0.005709729), ('layer4.1.relu_0_output_0', 95, 0.0058160233), ('layer4.1.relu_0_output_0', 69, 0.0058355755), ('layer4.1.relu_0_output_0', 41, 0.0058645005), ('layer3.1.relu_0_output_0', 21, 0.00588185), ('layer2.0.relu_0_output_0', 74, 0.005953421), ('layer3.0.relu_0_output_0', 127, 0.00607974), ('layer4.0.relu_0_output_0', 65, 0.006213589), ('layer4.0.relu_0_output_0', 123, 0.0062163444), ('layer4.1.relu_0_output_0', 49, 0.00624936), ('layer4.1.relu_0_output_0', 138, 0.0063573327), ('layer4.1.relu_0_output_0', 154, 0.0063955938), ('layer2.0.relu_0_output_0', 47, 0.0065184156), ('layer2.1.relu_0_output_0', 9, 0.0066991383), ('layer4.0.relu_0_output_0', 104, 0.0069481432), ('layer3.1.relu_0_output_0', 9, 0.006959167), ('layer4.1.relu_0_output_0', 15, 0.006987668), ('layer4.1.relu_0_output_0', 46, 0.0070580724), ('layer4.1.relu_0_output_0', 8, 0.0071084364), ('layer3.0.relu_0_output_0', 116, 0.0071357624), ('layer4.1.relu_0_output_0', 71, 0.007154534), ('layer4.1.relu_0_output_0', 110, 0.0071550207), ('layer4.1.relu_0_output_0', 10, 0.007172039), ('layer3.0.relu_0_output_0', 19, 0.007293524), ('layer3.1.relu_0_output_0', 26, 0.0073932162), ('layer3.1.relu_0_output_0', 65, 0.0076662893), ('layer4.1.relu_0_output_0', 50, 0.007673946), ('layer2.1.relu_0_output_0', 90, 0.0077383113), ('layer2.1.relu_0_output_0', 15, 0.007840803), ('layer3.0.relu_0_output_0', 45, 0.0079243155), ('layer4.1.relu_0_output_0', 170, 0.007958945), ('layer4.1.relu_0_output_0', 168, 0.00796375), ('layer3.1.relu_0_output_0', 0, 0.008013132), ('layer4.0.relu_0_output_0', 4, 0.008108666)]\n",
      "Reduce output channels for conv layer layer1.0. from 54 to 53\n",
      "Reduce bn layer layer1.0. from 54 to 53\n",
      "Reduce output channels for conv layer layer1.1. from 57 to 54\n",
      "Reduce bn layer layer1.1. from 57 to 54\n",
      "Reduce output channels for conv layer layer2.0. from 91 to 84\n",
      "Reduce bn layer layer2.0. from 91 to 84\n",
      "Reduce output channels for conv layer layer2.1. from 94 to 88\n",
      "Reduce bn layer layer2.1. from 94 to 88\n",
      "Reduce output channels for conv layer layer3.0. from 157 to 146\n",
      "Reduce bn layer layer3.0. from 157 to 146\n",
      "Reduce output channels for conv layer layer3.1. from 167 to 154\n",
      "Reduce bn layer layer3.1. from 167 to 154\n",
      "Reduce output channels for conv layer layer4.0. from 253 to 231\n",
      "Reduce bn layer layer4.0. from 253 to 231\n",
      "Reduce output channels for conv layer layer4.1. from 247 to 210\n",
      "Reduce bn layer layer4.1. from 247 to 210\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-225012-lkph for pruning step 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-22-50-13-041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 22:50:14 Starting - Starting the training job...\n",
      "2020-05-02 22:50:16 Starting - Launching requested ML instances...\n",
      "2020-05-02 22:51:11 Starting - Preparing the instances for training............\n",
      "2020-05-02 22:52:50 Downloading - Downloading input data......\n",
      "2020-05-02 22:53:47 Training - Downloading the training image...........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,025 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,052 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,053 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,702 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,702 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,702 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:54,703 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpkzlkjebi/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=20337554 sha256=96906641b450c1651e17ced3e1deaf67ba9977b16530c5a6b797dcb3ac255c84\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g_44e7hn/wheels/b0/f0/fe/f85dcdd09f3fdee354ffecf63c2494e9fdd5cf0d173265b6d4\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 22:55:58,965 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-22-50-13-041\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-50-13-041/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-50-13-041/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-22-50-13-041\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-50-13-041/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-02 22:55:52 Training - Training image download completed. Training in progress.\u001b[34m[2020-05-02 22:56:01.063 algo-1:48 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:56:01.063 algo-1:48 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:56:01.063 algo-1:48 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 22:56:03.782 algo-1:48 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3355\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8358\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.2990\u001b[0m\n",
      "\n",
      "2020-05-02 23:04:39 Uploading - Uploading generated training model\u001b[34macc:0.8507\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.2797\u001b[0m\n",
      "\u001b[34macc:0.8507\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2711\u001b[0m\n",
      "\u001b[34macc:0.8682\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2764\u001b[0m\n",
      "\u001b[34macc:0.8582\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2648\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2569\u001b[0m\n",
      "\u001b[34macc:0.8582\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2624\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2569\u001b[0m\n",
      "\u001b[34macc:0.8557\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2383\u001b[0m\n",
      "\u001b[34macc:0.8632\u001b[0m\n",
      "\u001b[34m[2020-05-02 23:04:37.049 algo-1:48 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 23:04:37,404 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 23:04:57 Completed - Training job completed\n",
      "Training seconds: 727\n",
      "Billable seconds: 727\n",
      "Training job pytorch-training-2020-05-02-22-50-13-041  finished.\n",
      "[2020-05-02 23:05:33.167 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-22-50-13-041/debug-output\n",
      "[2020-05-02 23:05:33.669 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 23:05:34.689 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer2.1.relu_0_output_0', 38, 3.127304e-05), ('layer4.1.relu_0_output_0', 125, 6.247014e-05), ('layer3.1.relu_0_output_0', 62, 8.918751e-05), ('layer3.1.relu_0_output_0', 65, 0.00015852008), ('layer4.1.relu_0_output_0', 93, 0.00017876847), ('layer4.0.relu_0_output_0', 159, 0.00019423263), ('layer4.0.relu_0_output_0', 142, 0.0002885375), ('layer3.0.relu_0_output_0', 58, 0.00032259992), ('layer3.1.relu_0_output_0', 114, 0.0004376465), ('layer3.1.relu_0_output_0', 101, 0.0004904088), ('layer3.0.relu_0_output_0', 111, 0.00075624476), ('layer3.1.relu_0_output_0', 57, 0.0009339854), ('layer3.0.relu_0_output_0', 52, 0.0012617441), ('layer4.1.relu_0_output_0', 115, 0.0013339884), ('layer4.1.relu_0_output_0', 51, 0.0013390688), ('layer3.0.relu_0_output_0', 64, 0.001344064), ('layer1.1.relu_0_output_0', 22, 0.0013611524), ('layer3.1.relu_0_output_0', 120, 0.0015156337), ('layer4.1.relu_0_output_0', 187, 0.0018654123), ('layer1.0.relu_0_output_0', 3, 0.0019445034), ('layer2.1.relu_0_output_0', 64, 0.0020056253), ('layer3.1.relu_0_output_0', 108, 0.0023269618), ('layer4.0.relu_0_output_0', 71, 0.0024140708), ('layer4.1.relu_0_output_0', 39, 0.0024338951), ('layer3.1.relu_0_output_0', 21, 0.0025042295), ('layer4.0.relu_0_output_0', 178, 0.0025487642), ('layer4.0.relu_0_output_0', 64, 0.002681092), ('layer2.0.relu_0_output_0', 60, 0.0026844712), ('layer4.1.relu_0_output_0', 197, 0.0027666586), ('layer4.0.relu_0_output_0', 125, 0.002804951), ('layer3.1.relu_0_output_0', 8, 0.002864934), ('layer4.1.relu_0_output_0', 1, 0.0029001883), ('layer4.0.relu_0_output_0', 205, 0.0030198991), ('layer3.1.relu_0_output_0', 52, 0.0030433543), ('layer2.0.relu_0_output_0', 80, 0.003154749), ('layer4.0.relu_0_output_0', 153, 0.0031907149), ('layer2.1.relu_0_output_0', 62, 0.0033531839), ('layer4.1.relu_0_output_0', 6, 0.003385136), ('layer4.1.relu_0_output_0', 35, 0.0034488586), ('layer4.0.relu_0_output_0', 166, 0.0036027525), ('layer2.0.relu_0_output_0', 9, 0.0036560523), ('layer3.1.relu_0_output_0', 104, 0.0037754476), ('layer4.0.relu_0_output_0', 218, 0.003821657), ('layer3.1.relu_0_output_0', 23, 0.003879348), ('layer3.0.relu_0_output_0', 104, 0.003987651), ('layer4.0.relu_0_output_0', 29, 0.004018635), ('layer1.1.relu_0_output_0', 1, 0.0040466078), ('layer4.1.relu_0_output_0', 57, 0.0040881108), ('layer1.1.relu_0_output_0', 18, 0.0041921167), ('layer4.1.relu_0_output_0', 208, 0.0042031603), ('layer4.1.relu_0_output_0', 205, 0.004206406), ('layer4.1.relu_0_output_0', 182, 0.0043477225), ('layer4.1.relu_0_output_0', 136, 0.0044614803), ('layer2.0.relu_0_output_0', 43, 0.004555306), ('layer4.1.relu_0_output_0', 110, 0.0046102484), ('layer4.0.relu_0_output_0', 23, 0.004835599), ('layer1.1.relu_0_output_0', 12, 0.0048661605), ('layer4.0.relu_0_output_0', 57, 0.0049962793), ('layer4.0.relu_0_output_0', 97, 0.005031), ('layer4.0.relu_0_output_0', 202, 0.0050479267), ('layer4.0.relu_0_output_0', 126, 0.00514061), ('layer1.0.relu_0_output_0', 39, 0.005142226), ('layer3.0.relu_0_output_0', 141, 0.0051796944), ('layer4.1.relu_0_output_0', 101, 0.005253488), ('layer4.1.relu_0_output_0', 14, 0.00540764), ('layer3.0.relu_0_output_0', 79, 0.005448759), ('layer4.1.relu_0_output_0', 153, 0.005583032), ('layer4.1.relu_0_output_0', 13, 0.0056245145), ('layer4.1.relu_0_output_0', 67, 0.005715998), ('layer4.1.relu_0_output_0', 68, 0.0057510086), ('layer3.0.relu_0_output_0', 61, 0.0058202865), ('layer4.0.relu_0_output_0', 15, 0.0058366456), ('layer3.0.relu_0_output_0', 53, 0.0058437395), ('layer4.0.relu_0_output_0', 77, 0.0059905266), ('layer4.1.relu_0_output_0', 99, 0.0060053603), ('layer4.1.relu_0_output_0', 192, 0.0060096732), ('layer4.1.relu_0_output_0', 45, 0.00601134), ('layer2.1.relu_0_output_0', 68, 0.0062414506), ('layer4.1.relu_0_output_0', 78, 0.0062855682), ('layer3.1.relu_0_output_0', 83, 0.0063006077), ('layer3.0.relu_0_output_0', 113, 0.006406914), ('layer4.0.relu_0_output_0', 3, 0.0064090877), ('layer3.1.relu_0_output_0', 121, 0.0067307153), ('layer3.0.relu_0_output_0', 4, 0.006733835), ('layer2.1.relu_0_output_0', 66, 0.0067871558), ('layer3.0.relu_0_output_0', 45, 0.0069342023), ('layer3.1.relu_0_output_0', 32, 0.0070385234), ('layer4.1.relu_0_output_0', 169, 0.0070677833), ('layer2.0.relu_0_output_0', 49, 0.0070949104), ('layer4.0.relu_0_output_0', 103, 0.0072090835), ('layer2.1.relu_0_output_0', 76, 0.007531516), ('layer4.0.relu_0_output_0', 141, 0.0076255365), ('layer3.1.relu_0_output_0', 95, 0.0077443486), ('layer4.0.relu_0_output_0', 227, 0.007793556), ('layer4.0.relu_0_output_0', 113, 0.007850207), ('layer3.0.relu_0_output_0', 99, 0.007868691), ('layer1.0.relu_0_output_0', 7, 0.007875137), ('layer4.1.relu_0_output_0', 103, 0.008004959), ('layer4.1.relu_0_output_0', 195, 0.008042653), ('layer4.1.relu_0_output_0', 74, 0.008160709)]\n",
      "Reduce output channels for conv layer layer1.0. from 53 to 50\n",
      "Reduce bn layer layer1.0. from 53 to 50\n",
      "Reduce output channels for conv layer layer1.1. from 54 to 50\n",
      "Reduce bn layer layer1.1. from 54 to 50\n",
      "Reduce output channels for conv layer layer2.0. from 84 to 79\n",
      "Reduce bn layer layer2.0. from 84 to 79\n",
      "Reduce output channels for conv layer layer2.1. from 88 to 82\n",
      "Reduce bn layer layer2.1. from 88 to 82\n",
      "Reduce output channels for conv layer layer3.0. from 146 to 133\n",
      "Reduce bn layer layer3.0. from 146 to 133\n",
      "Reduce output channels for conv layer layer3.1. from 154 to 138\n",
      "Reduce bn layer layer3.1. from 154 to 138\n",
      "Reduce output channels for conv layer layer4.0. from 231 to 208\n",
      "Reduce bn layer layer4.0. from 231 to 208\n",
      "Reduce output channels for conv layer layer4.1. from 210 to 180\n",
      "Reduce bn layer layer4.1. from 210 to 180\n",
      "Saving pruned model\n",
      "Created new trial Trial-2020-05-02-230709-doqc for pruning step 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2020-05-02-23-07-10-116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-02 23:07:12 Starting - Starting the training job...\n",
      "2020-05-02 23:07:13 Starting - Launching requested ML instances...\n",
      "2020-05-02 23:08:08 Starting - Preparing the instances for training.........\n",
      "2020-05-02 23:09:30 Downloading - Downloading input data.........\n",
      "2020-05-02 23:10:58 Training - Downloading the training image...........\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:51,469 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:51,498 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:52,920 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:53,531 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:53,531 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:53,531 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:53,532 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpj8q42p84/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=18163143 sha256=81b5e4c4a34882f7bc487199a66f2035515c4ae7b35de5cf86914f4df8a81f68\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4nuwudlw/wheels/57/a9/fd/0be42a1230b2a68296c1a64febc8f2daefc5120f98345ddcf4\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 20.0.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-02 23:12:57,681 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-05-02-23-07-10-116\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-23-07-10-116/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-23-07-10-116/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-05-02-23-07-10-116\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-23-07-10-116/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --epochs 10\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-02 23:12:50 Training - Training image download completed. Training in progress.\u001b[34m[2020-05-02 23:12:59.914 algo-1:48 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 23:12:59.914 algo-1:48 INFO hook.py:152] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34m[2020-05-02 23:12:59.914 algo-1:48 INFO hook.py:197] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34m[2020-05-02 23:13:02.696 algo-1:48 INFO hook.py:326] Monitoring the collections: losses, custom_collection\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [1/10], loss:0.3404\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torchvision.models.resnet.BasicBlock' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\u001b[0m\n",
      "\u001b[34macc:0.8333\n",
      "  warnings.warn(msg, SourceChangeWarning)\u001b[0m\n",
      "\u001b[34mepoch [2/10], loss:0.3274\u001b[0m\n",
      "\n",
      "2020-05-02 23:21:39 Uploading - Uploading generated training model\u001b[34macc:0.8483\u001b[0m\n",
      "\u001b[34mepoch [3/10], loss:0.3164\u001b[0m\n",
      "\u001b[34macc:0.8607\u001b[0m\n",
      "\u001b[34mepoch [4/10], loss:0.2962\u001b[0m\n",
      "\u001b[34macc:0.8433\u001b[0m\n",
      "\u001b[34mepoch [5/10], loss:0.2912\u001b[0m\n",
      "\u001b[34macc:0.8532\u001b[0m\n",
      "\u001b[34mepoch [6/10], loss:0.2884\u001b[0m\n",
      "\u001b[34macc:0.8657\u001b[0m\n",
      "\u001b[34mepoch [7/10], loss:0.2703\u001b[0m\n",
      "\u001b[34macc:0.8582\u001b[0m\n",
      "\u001b[34mepoch [8/10], loss:0.2678\u001b[0m\n",
      "\u001b[34macc:0.8582\u001b[0m\n",
      "\u001b[34mepoch [9/10], loss:0.2595\u001b[0m\n",
      "\u001b[34macc:0.8532\u001b[0m\n",
      "\u001b[34mepoch [10/10], loss:0.2647\u001b[0m\n",
      "\u001b[34macc:0.8408\u001b[0m\n",
      "\u001b[34m[2020-05-02 23:21:36.548 algo-1:48 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-05-02 23:21:36,927 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-02 23:21:57 Completed - Training job completed\n",
      "Training seconds: 747\n",
      "Billable seconds: 747\n",
      "Training job pytorch-training-2020-05-02-23-07-10-116  finished.\n",
      "[2020-05-02 23:22:30.184 ip-172-16-82-160:32640 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-east-2-005166108777/pytorch-training-2020-05-02-23-07-10-116/debug-output\n",
      "[2020-05-02 23:22:30.661 ip-172-16-82-160:32640 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2020-05-02 23:22:31.677 ip-172-16-82-160:32640 INFO trial.py:210] Loaded all steps\n",
      "The 100 smallest filters [('layer4.0.relu_0_output_0', 188, 2.238411e-05), ('layer3.1.relu_0_output_0', 91, 0.000184673), ('layer3.1.relu_0_output_0', 123, 0.00041213125), ('layer3.1.relu_0_output_0', 75, 0.00049651146), ('layer3.1.relu_0_output_0', 131, 0.0007076547), ('layer3.1.relu_0_output_0', 118, 0.0007393059), ('layer4.1.relu_0_output_0', 151, 0.00097596494), ('layer4.1.relu_0_output_0', 20, 0.0011072833), ('layer4.1.relu_0_output_0', 30, 0.0011393332), ('layer4.1.relu_0_output_0', 161, 0.0012338371), ('layer2.1.relu_0_output_0', 9, 0.0013545682), ('layer4.1.relu_0_output_0', 105, 0.0016412364), ('layer3.1.relu_0_output_0', 0, 0.0016831232), ('layer4.1.relu_0_output_0', 126, 0.0017731894), ('layer4.0.relu_0_output_0', 22, 0.0019119297), ('layer2.0.relu_0_output_0', 17, 0.001984258), ('layer4.1.relu_0_output_0', 123, 0.0024754205), ('layer1.0.relu_0_output_0', 16, 0.0027405538), ('layer1.0.relu_0_output_0', 37, 0.002816755), ('layer2.0.relu_0_output_0', 63, 0.002839194), ('layer3.1.relu_0_output_0', 33, 0.00294276), ('layer4.0.relu_0_output_0', 77, 0.0031157916), ('layer3.0.relu_0_output_0', 93, 0.0035566643), ('layer1.1.relu_0_output_0', 22, 0.0036045886), ('layer4.0.relu_0_output_0', 10, 0.003636304), ('layer3.0.relu_0_output_0', 55, 0.0036587208), ('layer4.0.relu_0_output_0', 53, 0.0037829569), ('layer3.0.relu_0_output_0', 24, 0.0038192698), ('layer4.1.relu_0_output_0', 69, 0.0038430651), ('layer4.1.relu_0_output_0', 118, 0.0038783439), ('layer4.0.relu_0_output_0', 134, 0.0039231223), ('layer3.1.relu_0_output_0', 132, 0.004157716), ('layer4.0.relu_0_output_0', 189, 0.0041926336), ('layer3.1.relu_0_output_0', 111, 0.004209915), ('layer3.0.relu_0_output_0', 115, 0.0042285398), ('layer3.0.relu_0_output_0', 104, 0.0044224053), ('layer4.0.relu_0_output_0', 200, 0.0047746184), ('layer2.1.relu_0_output_0', 65, 0.004834051), ('layer4.1.relu_0_output_0', 17, 0.0048560454), ('layer2.1.relu_0_output_0', 25, 0.004879182), ('layer1.0.relu_0_output_0', 6, 0.0049448228), ('layer4.1.relu_0_output_0', 75, 0.0051024263), ('layer3.1.relu_0_output_0', 73, 0.0051042666), ('layer3.1.relu_0_output_0', 13, 0.0051162653), ('layer3.1.relu_0_output_0', 49, 0.0051919897), ('layer4.1.relu_0_output_0', 13, 0.0052621895), ('layer4.0.relu_0_output_0', 158, 0.005349297), ('layer4.0.relu_0_output_0', 198, 0.0053751073), ('layer3.1.relu_0_output_0', 51, 0.005597477), ('layer3.0.relu_0_output_0', 49, 0.005630545), ('layer4.0.relu_0_output_0', 1, 0.0057535623), ('layer4.0.relu_0_output_0', 45, 0.005850217), ('layer4.0.relu_0_output_0', 183, 0.005893918), ('layer3.1.relu_0_output_0', 44, 0.006057424), ('layer4.0.relu_0_output_0', 115, 0.0062146476), ('layer4.0.relu_0_output_0', 93, 0.0062495763), ('layer4.0.relu_0_output_0', 2, 0.0063214065), ('layer4.1.relu_0_output_0', 142, 0.0064032013), ('layer2.1.relu_0_output_0', 39, 0.0064762854), ('layer2.1.relu_0_output_0', 38, 0.0065501826), ('layer1.0.relu_0_output_0', 3, 0.006832025), ('layer3.1.relu_0_output_0', 61, 0.006858205), ('layer4.0.relu_0_output_0', 84, 0.00698194), ('layer4.0.relu_0_output_0', 17, 0.007034331), ('layer4.0.relu_0_output_0', 155, 0.0070663067), ('layer3.0.relu_0_output_0', 127, 0.0073934565), ('layer3.1.relu_0_output_0', 112, 0.007447145), ('layer4.0.relu_0_output_0', 16, 0.007481573), ('layer4.0.relu_0_output_0', 71, 0.0075850924), ('layer3.1.relu_0_output_0', 130, 0.007712284), ('layer4.1.relu_0_output_0', 10, 0.007742213), ('layer4.0.relu_0_output_0', 20, 0.007861128), ('layer4.1.relu_0_output_0', 165, 0.008137364), ('layer3.1.relu_0_output_0', 40, 0.0083372705), ('layer2.0.relu_0_output_0', 50, 0.008365561), ('layer3.1.relu_0_output_0', 92, 0.008526013), ('layer4.0.relu_0_output_0', 27, 0.008548737), ('layer4.1.relu_0_output_0', 58, 0.008581884), ('layer4.1.relu_0_output_0', 57, 0.008647121), ('layer4.1.relu_0_output_0', 52, 0.008852782), ('layer2.0.relu_0_output_0', 73, 0.008959821), ('layer3.0.relu_0_output_0', 22, 0.008989604), ('layer4.0.relu_0_output_0', 102, 0.009226852), ('layer4.1.relu_0_output_0', 100, 0.009484447), ('layer4.1.relu_0_output_0', 29, 0.009717042), ('layer3.1.relu_0_output_0', 89, 0.00987572), ('layer4.0.relu_0_output_0', 127, 0.009958232), ('layer4.1.relu_0_output_0', 24, 0.009966504), ('layer3.1.relu_0_output_0', 34, 0.010011298), ('layer3.0.relu_0_output_0', 107, 0.0100790365), ('layer2.1.relu_0_output_0', 19, 0.010533458), ('layer4.1.relu_0_output_0', 129, 0.010685296), ('layer3.1.relu_0_output_0', 38, 0.010752965), ('layer3.1.relu_0_output_0', 126, 0.01089033), ('layer3.1.relu_0_output_0', 137, 0.011004575), ('layer2.1.relu_0_output_0', 53, 0.011066488), ('layer4.1.relu_0_output_0', 39, 0.011177722), ('layer4.0.relu_0_output_0', 150, 0.011329148), ('layer4.0.relu_0_output_0', 130, 0.011346184), ('layer2.1.relu_0_output_0', 21, 0.01156794)]\n",
      "Reduce output channels for conv layer layer1.0. from 50 to 46\n",
      "Reduce bn layer layer1.0. from 50 to 46\n",
      "Reduce output channels for conv layer layer1.1. from 50 to 49\n",
      "Reduce bn layer layer1.1. from 50 to 49\n",
      "Reduce output channels for conv layer layer2.0. from 79 to 75\n",
      "Reduce bn layer layer2.0. from 79 to 75\n",
      "Reduce output channels for conv layer layer2.1. from 82 to 74\n",
      "Reduce bn layer layer2.1. from 82 to 74\n",
      "Reduce output channels for conv layer layer3.0. from 133 to 124\n",
      "Reduce bn layer layer3.0. from 133 to 124\n",
      "Reduce output channels for conv layer layer3.1. from 138 to 114\n",
      "Reduce bn layer layer3.1. from 138 to 114\n",
      "Reduce output channels for conv layer layer4.0. from 208 to 181\n",
      "Reduce bn layer layer4.0. from 208 to 181\n",
      "Reduce output channels for conv layer layer4.1. from 180 to 157\n",
      "Reduce bn layer layer4.1. from 180 to 157\n",
      "Saving pruned model\n"
     ]
    }
   ],
   "source": [
    "# start iterative pruning\n",
    "for pruning_step in range(10):\n",
    "    \n",
    "    #create new trial for this pruning step\n",
    "    smexperiments_trial = Trial.create(\n",
    "        experiment_name=experiment_name,\n",
    "        sagemaker_boto_client=sagemaker_boto_client\n",
    "    )\n",
    "    experiment_config[\"TrialName\"] = smexperiments_trial.trial_name\n",
    "\n",
    "    print(\"Created new trial\", smexperiments_trial.trial_name, \"for pruning step\", pruning_step)\n",
    "    \n",
    "    #start training job\n",
    "    estimator = PyTorch(role=sagemaker.get_execution_role(),\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.p2.xlarge',\n",
    "                  train_volume_size=400,\n",
    "                  source_dir='src',\n",
    "                  entry_point='train.py',\n",
    "                  framework_version='1.3.1',\n",
    "                  py_version='py3',\n",
    "                  metric_definitions=[ {'Name':'train:loss', 'Regex':'loss:(.*?)'}, {'Name':'eval:acc', 'Regex':'acc:(.*?)'} ],\n",
    "                  enable_sagemaker_metrics=True,\n",
    "                  hyperparameters = {'epochs': 10},\n",
    "                  debugger_hook_config = debugger_hook_config\n",
    "        )\n",
    "    \n",
    "    #start training job\n",
    "    estimator.fit(inputs={'train': 's3://{}/101_ObjectCategories_train'.format(bucket), \n",
    "                      'test': 's3://{}/101_ObjectCategories_test'.format(bucket)}, \n",
    "              experiment_config=experiment_config)\n",
    "\n",
    "\n",
    "    print(\"Training job\", estimator.latest_training_job.name, \" finished.\")\n",
    "    \n",
    "    # read tensors\n",
    "    path = estimator.latest_job_debugger_artifacts_path()\n",
    "    smdebug_trial = create_trial(path)\n",
    "    \n",
    "    # compute filter ranks and get 100 smallest filters\n",
    "    filters = compute_filter_ranks(smdebug_trial, activation_outputs, gradients)\n",
    "    filters_normalized = normalize_filter_ranks(filters)  \n",
    "    filters_list = get_smallest_filters(filters_normalized, 100)\n",
    "        \n",
    "    #load previous model \n",
    "    checkpoint = torch.load(\"src/model_checkpoint\")\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    #prune model\n",
    "    step = smdebug_trial.steps(mode=modes.TRAIN)[-1]\n",
    "    model = model_resnet.prune(model, \n",
    "                        filters_list, \n",
    "                        smdebug_trial, \n",
    "                        step)\n",
    "    \n",
    "    print(\"Saving pruned model\")\n",
    "    \n",
    "    # save pruned model\n",
    "    checkpoint = {'model': model,\n",
    "                  'state_dict': model.state_dict()}\n",
    "    torch.save(checkpoint, 'src/model_checkpoint')\n",
    "    \n",
    "    #clean up\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the iterative model pruning is running, we can track and visualize our experiment in SageMaker Studio. In our training script we use SageMaker debugger's `save_scalar` method to store the number of parameters in the model and the model accuracy. So we can visualize those in Studio or use the `ExperimentAnalytics` module to read and plot the values directly in the notebook.\n",
    "\n",
    "Initially the model consisted of 11 million parameters. After 11 iterations, the number of parameters was reduced to 270k, while accuracy increased to 91% and then started dropping after 8 pruning iteration.\n",
    "\n",
    "This means that the best accuracy can be reached if the model has a size of about 4 million parameters, while shrinking model size about 3x!\n",
    "\n",
    "![](images/results_resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.865672\n",
      "1     0.868159\n",
      "2     0.880597\n",
      "3     0.893035\n",
      "4     0.890547\n",
      "5     0.907960\n",
      "6     0.902985\n",
      "7     0.900498\n",
      "8     0.898010\n",
      "9     0.880597\n",
      "10    0.848259\n",
      "Name: scalar/accuracy_EVAL - Max, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(experiment_name=experiment_name)\n",
    "accuracy = trial_component_analytics.dataframe()['scalar/accuracy_EVAL - Max']\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional: run iterative model pruning with custom rule\n",
    "\n",
    "In the previous example, we have seen that accuracy drops when the model has less than 22 million parameters. Clearly, we want to stop our experiment once we reach this point. We can define a custom rule that returns `True` if the accuracy drops by a certain percentage. You can find an example implementation in `custom_rule/check_accuracy.py`. Before we can use the rule we have to define a custom rule configuration:\n",
    "\n",
    "```python\n",
    "\n",
    "from sagemaker.debugger import Rule, CollectionConfig, rule_configs\n",
    "\n",
    "check_accuracy_rule = Rule.custom(\n",
    "    name='CheckAccuracy',\n",
    "    image_uri='759209512951.dkr.ecr.us-west-2.amazonaws.com/sagemaker-debugger-rule-evaluator:latest',\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    volume_size_in_gb=400,\n",
    "    source='custom_rule/check_accuracy.py',\n",
    "    rule_to_invoke='check_accuracy',\n",
    "    rule_parameters={\"previous_accuracy\": \"0.0\", \n",
    "                     \"threshold\": \"0.05\", \n",
    "                     \"predictions\": \"CrossEntropyLoss_0_input_0\", \n",
    "                     \"labels\":\"CrossEntropyLoss_0_input_1\"},\n",
    ")\n",
    "```\n",
    "\n",
    "The rule reads the inputs to the loss function, which are the model predictions and the labels. It computes the accuracy and returns `True` if its value has dropped by more than 5% otherwise `False`. \n",
    "\n",
    "In each pruning iteration, we need to pass the accuracy of the previous training job to the rule, which can be retrieved via the `ExperimentAnalytics` module.\n",
    "\n",
    "```python\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(experiment_name=experiment_name)\n",
    "accuracy = trial_component_analytics.dataframe()['scalar/accuracy_EVAL - Max'][0]\n",
    "```\n",
    "And overwrite the value in the rule configuration:\n",
    "\n",
    "```python\n",
    "check_accuracy_rule.rule_parameters[\"previous_accuracy\"] = str(accuracy)\n",
    "```\n",
    "\n",
    "In the PyTorch estimator we need to add the argument `rules = [check_accuracy_rule]`.\n",
    "We can create a CloudWatch alarm and use a Lambda function to stop the training. Detailed instructions can be found [here](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-debugger/tensorflow_action_on_rule). In each iteration we check the job status and if the previous job has been stopped, we exit the loop:\n",
    "\n",
    "```python\n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "\n",
    "if description['TrainingJobStatus'] == 'Stopped':\n",
    "      break\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
